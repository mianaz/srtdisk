[{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"converting-from-seurat-to-anndata-via-h5seurat","dir":"Articles","previous_headings":"","what":"Converting from Seurat to AnnData via h5Seurat","title":"Conversions: h5Seurat and AnnData","text":"demonstrate conversion Seurat object AnnData file, ’ll use pbmc3k.final dataset SeuratData - processed PBMC dataset clustering UMAP. fully processed Seurat object clustering dimensional reductions:   Converting Seurat object AnnData file two-step process: Save Seurat object h5Seurat file using SaveH5Seurat() Convert AnnData using Convert() can view AnnData file Scanpy: visualize cluster annotations:   conversion preserves expression patterns - CD14 shows consistent distribution tools.","code":"library(SeuratData) if (!\"pbmc3k.final\" %in% rownames(InstalledData())) {   InstallData(\"pbmc3k\") }  data(\"pbmc3k.final\", package = \"pbmc3k.SeuratData\") pbmc <- UpdateSeuratObject(pbmc3k.final) pbmc #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  3 layers present: counts, data, scale.data #>  2 dimensional reductions calculated: pca, umap DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5) + NoLegend() FeaturePlot(pbmc, features = \"CD14\", pt.size = 0.5) cat(\"Seurat layers:\", paste(Layers(pbmc), collapse = \", \"), \"\\n\") #> Seurat layers: counts, data, scale.data SaveH5Seurat(pbmc, filename = \"pbmc3k.h5Seurat\", overwrite = TRUE) Convert(\"pbmc3k.h5Seurat\", dest = \"h5ad\", overwrite = TRUE) import scanpy as sc adata = sc.read_h5ad(\"pbmc3k.h5ad\") print(adata) #> AnnData object with n_obs × n_vars = 2638 × 13714 #>     obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'seurat_annotations', 'percent.mt', 'RNA_snn_res.0.5', 'seurat_clusters' #>     var: 'vst.mean', 'vst.variance', 'vst.variance.expected', 'vst.variance.standardized', 'vst.variable' #>     uns: 'n_variable_features', 'neighbors', 'seurat' #>     obsm: 'X_pca', 'X_umap' #>     varm: 'PCs' #>     obsp: 'connectivities', 'distances' sc.pl.umap(adata, color='seurat_annotations', legend_loc='on data', legend_fontsize=8) sc.pl.umap(adata, color='CD14')"},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"converting-from-anndata-to-seurat-via-h5seurat","dir":"Articles","previous_headings":"","what":"Converting from AnnData to Seurat via h5Seurat","title":"Conversions: h5Seurat and AnnData","text":"demonstrate conversion AnnData Seurat, ’ll use colorectal cancer sample CellxGene ’s bundled package. View h5ad file Scanpy: CellxGene datasets use Ensembl IDs var_names default. feature_name column contains gene symbols. conversion, srtdisk automatically uses gene symbols feature_name available. Note data layers: conversion, AnnData’s X matrix (typically log-normalized data indicated log1p_total_counts obs) stored Seurat’s data layer. raw/X exists, becomes counts layer. Visualize scanpy conversion:   Convert Seurat:","code":"h5ad_path <- system.file(\"testdata\", \"crc_sample.h5ad\", package = \"srtdisk\") if (file.exists(h5ad_path)) {   file.copy(h5ad_path, \"crc_sample.h5ad\", overwrite = TRUE) } else {   download.file(     \"https://datasets.cellxgene.cziscience.com/91cf9a95-0b9a-4ece-b8eb-7b9e3409a0d3.h5ad\",     \"crc_sample.h5ad\", mode = \"wb\"   ) } #> [1] TRUE import scanpy as sc adata_crc = sc.read_h5ad(\"crc_sample.h5ad\") print(adata_crc) #> AnnData object with n_obs × n_vars = 935 × 25344 #>     obs: 'total_counts', 'log1p_total_counts', 'Sample ID', 'PhenoGraph_clusters', 'Patient', 'Primary Site', 'Sample Type', 'Site', 'DC 1', 'DC 2', 'DC 3', 'DC 4', 'Module Absorptive Intestine Score', 'Module EMT Score', 'Module Injury Repair Score', 'Module Squamous Score', 'Module Neuroendocrine Score', 'Module Endoderm Development Score', 'Module Tumor ISC-like Score', 'Module Secretory Intestine Score', 'Module Intestine Score', 'palantir_pseudotime', 'palantir_neuroendocrine_branch_probability', 'palantir_squamous_branch_probability', 'Fetal, Conserved', 'Module Osteoblast Score', 'Treatment', 'donor_id', 'development_stage_ontology_term_id', 'sex_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'disease_ontology_term_id', 'tissue_type', 'tissue_ontology_term_id', 'cell_type_ontology_term_id', 'assay_ontology_term_id', 'suspension_type', 'Tumor Status', 'is_primary_data', 'cell_type', 'assay', 'disease', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid' #>     var: 'total_counts', 'highly_variable', 'gene', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type' #>     uns: 'citation', 'default_embedding', 'neighbors', 'organism', 'organism_ontology_term_id', 'schema_reference', 'schema_version', 'title' #>     obsm: 'X_umap' sc.pl.umap(adata_crc, color='tissue') import pandas as pd  sc.pp.normalize_total(adata_crc, target_sum=1e4) sc.pp.log1p(adata_crc)  # Set gene symbols as var_names (force string conversion from Categorical) adata_crc.var_names = pd.Index(adata_crc.var['feature_name'].astype(str).values) adata_crc.var_names_make_unique()  adata_crc.write_h5ad(\"crc_normalized.h5ad\")  sc.pl.umap(adata_crc, color='EPCAM', use_raw=False, title='EPCAM') Convert(\"crc_normalized.h5ad\", dest = \"h5seurat\", overwrite = TRUE) crc <- LoadH5Seurat(\"crc_normalized.h5seurat\")  # Verify layer mapping: X -> data (log-normalized), raw/X -> counts (if exists) cat(\"Layers:\", paste(Layers(crc), collapse = \", \"), \"\\n\") #> Layers: counts, data cat(\"Data layer range:\", round(range(GetAssayData(crc, layer = \"data\")[1:100, 1:10]), 2), \"\\n\") #> Data layer range: 0 2.77 crc #> An object of class Seurat  #> 25344 features across 935 samples within 1 assay  #> Active assay: RNA (25344 features, 3466 variable features) #>  2 layers present: counts, data #>  1 dimensional reduction calculated: umap"},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"visualize-converted-data","dir":"Articles","previous_headings":"Converting from AnnData to Seurat via h5Seurat","what":"Visualize Converted Data","title":"Conversions: h5Seurat and AnnData","text":"UMAP coordinates normalized expression scanpy preserved:   conversion preserves expression patterns - EPCAM shows consistent distribution tools.","code":"DimPlot(crc, reduction = \"umap\", group.by = \"tissue\", pt.size = 0.5) FeaturePlot(crc, features = \"EPCAM\", pt.size = 0.5)"},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"visium-spatial-data-conversion","dir":"Articles","previous_headings":"","what":"Visium Spatial Data Conversion","title":"Conversions: h5Seurat and AnnData","text":"spatial transcriptomics data, use stxBrain dataset SeuratData (Visium v2 format):  Convert h5ad: View Python Squidpy:","code":"library(SeuratData) if (!\"stxBrain\" %in% rownames(InstalledData())) {   InstallData(\"stxBrain\") }  brain <- UpdateSeuratObject(LoadData(\"stxBrain\", type = \"anterior1\")) brain <- NormalizeData(brain) cat(\"Layers:\", paste(Layers(brain), collapse = \", \"), \"\\n\") #> Layers: counts, data  SpatialFeaturePlot(brain, features = \"Hpca\") SaveH5Seurat(brain, filename = \"stxBrain.h5Seurat\", overwrite = TRUE) Convert(\"stxBrain.h5Seurat\", dest = \"h5ad\", overwrite = TRUE) import squidpy as sq import scanpy as sc  adata_spatial = sc.read_h5ad(\"stxBrain.h5ad\") print(adata_spatial) #> AnnData object with n_obs × n_vars = 2696 × 31053 #>     obs: 'orig.ident', 'nCount_Spatial', 'nFeature_Spatial', 'slice', 'region' #>     var: 'features' #>     uns: 'seurat', 'spatial' #>     obsm: 'spatial'  sq.pl.spatial_scatter(adata_spatial, color=\"Hpca\", library_id=\"anterior1\",                       img_res_key=\"lowres\", size=1.5, use_raw=False)"},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"multi-assay-conversion-cite-seq","dir":"Articles","previous_headings":"","what":"Multi-assay Conversion (CITE-seq)","title":"Conversions: h5Seurat and AnnData","text":"multi-modal data like CITE-seq, assay must converted separately since h5ad format supports single matrix per file. Conversion behavior: assay specified: default assay converted Single assay specified: specific assay converted Multiple assays: Must call function multiple times, per assay example uses cbmc dataset SeuratData: Verify converted file scanpy: h5ad file preserves full structure: gene expression matrix (X), cell metadata (obs), gene info (var). Convert ADT assay separately: assay produces separate h5ad file cell metadata different features. Note h5mu format: true multi-modal interoperability, consider MuData/h5mu format scverse ecosystem. MuDataSeurat R package provides ReadH5MU() WriteH5MU() functions Seurat objects. allows storing multiple modalities single file shared cell annotations, though Seurat-specific features may round-trip perfectly.","code":"library(SeuratData) if (!\"cbmc\" %in% rownames(InstalledData())) {   InstallData(\"cbmc\") } data(\"cbmc\", package = \"cbmc.SeuratData\") cbmc <- UpdateSeuratObject(cbmc)  cat(\"Assays:\", paste(Assays(cbmc), collapse = \", \"), \"\\n\") #> Assays: RNA, ADT  # Convert RNA assay (default) DefaultAssay(cbmc) <- \"RNA\" SaveH5Seurat(cbmc, \"cbmc_rna.h5seurat\", overwrite = TRUE) Convert(\"cbmc_rna.h5seurat\", dest = \"h5ad\", overwrite = TRUE) import scanpy as sc adata_rna = sc.read_h5ad(\"cbmc_rna.h5ad\") print(adata_rna) #> AnnData object with n_obs × n_vars = 8617 × 20501 #>     obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'nCount_ADT', 'nFeature_ADT', 'rna_annotations', 'protein_annotations' #>     var: 'features' #>     uns: 'seurat' print(\"obs columns:\", list(adata_rna.obs.columns)[:10]) #> obs columns: ['orig.ident', 'nCount_RNA', 'nFeature_RNA', 'nCount_ADT', 'nFeature_ADT', 'rna_annotations', 'protein_annotations'] # Convert ADT assay DefaultAssay(cbmc) <- \"ADT\" SaveH5Seurat(cbmc, \"cbmc_adt.h5seurat\", overwrite = TRUE) Convert(\"cbmc_adt.h5seurat\", dest = \"h5ad\", overwrite = TRUE) import scanpy as sc adata_adt = sc.read_h5ad(\"cbmc_adt.h5ad\") print(adata_adt) #> AnnData object with n_obs × n_vars = 8617 × 10 #>     obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'nCount_ADT', 'nFeature_ADT', 'rna_annotations', 'protein_annotations' #>     var: 'features' #>     uns: 'seurat' print(\"ADT features:\", list(adata_adt.var_names)[:10]) #> ADT features: ['CD3', 'CD4', 'CD8', 'CD45RA', 'CD56', 'CD16', 'CD11c', 'CD14', 'CD19', 'CD34']"},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"spatial-h5ad-to-seurat","dir":"Articles","previous_headings":"","what":"Spatial h5ad to Seurat","title":"Conversions: h5Seurat and AnnData","text":"Converting native spatial h5ad files Seurat fully supported. use Visium colon sample CellxGene processed scanpy/squidpy standard workflows: View native spatial h5ad Python: Normalize, set gene symbols, save conversion:  Convert Seurat: Verify spatial data preserved:  Note: Spatial images coordinates preserved conversion. scanpy-specific structures (like neighbor graphs obsp) may need recomputed Seurat using FindNeighbors().","code":"cache_dir <- tools::R_user_dir(\"srtdisk\", which = \"cache\") cache_path <- file.path(cache_dir, \"visium_colon.h5ad\")  if (!file.exists(cache_path)) {   dir.create(cache_dir, recursive = TRUE, showWarnings = FALSE)   message(\"Downloading Visium colon dataset (~1.7GB)...\")   download.file(     \"https://datasets.cellxgene.cziscience.com/ab9f4860-c0e3-444b-a982-38c13f0be6f5.h5ad\",     cache_path, mode = \"wb\"   ) } file.copy(cache_path, \"visium_colon.h5ad\", overwrite = TRUE) #> [1] TRUE import scanpy as sc adata_spatial = sc.read_h5ad(\"visium_colon.h5ad\") print(adata_spatial) #> AnnData object with n_obs × n_vars = 4992 × 32397 #>     obs: 'in_tissue', 'array_row', 'array_col', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'sangerID', 'region', 'donor_type', 'age', 'facility', 'flushed', 'annotation_final', 'Adip1', 'Adip2', 'Adip3', 'B', 'B_plasma', 'CD14+Mo', 'CD16+Mo', 'CD4+T_act', 'CD4+T_naive', 'CD8+T_cytox', 'CD8+T_em', 'CD8+T_te', 'CD8+T_trans', 'DC', 'EC10_CMC-like', 'EC1_cap', 'EC2_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven', 'EC7_endocardial', 'EC8_ln', 'FB1', 'FB2', 'FB3', 'FB4_activated', 'FB5', 'FB6', 'ILC', 'LYVE1+IGF1+MP', 'LYVE1+MP_cycling', 'LYVE1+TIMD4+MP', 'MAIT-like', 'Mast', 'Meso', 'MoMP', 'NC1_glial', 'NC2_glial_NGF+', 'NK_CD16hi', 'NK_CD56hi', 'Neut', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SAN_P_cell', 'SMC1_basic', 'SMC2_art', 'T/NK_cycling', 'aCM1', 'aCM2', 'aCM3', 'aCM4', 'AVN_bundle_cell', 'PC4_CMC-like', 'vCM1', 'vCM2', 'vCM3_stressed', 'vCM4', 'vCM5', 'AVN_P_cell', 'CD4+T_Tfh', 'CD4+T_Th1', 'CD4+T_Th2', 'CD4+T_reg', 'NC5_glial', 'aCM5', 'Adip4', 'NC3_glial', 'NC6_schwann', 'EC9_FB-like', 'gdT', 'Adip1_abundance', 'Adip2_abundance', 'Adip3_abundance', 'B_abundance', 'B_plasma_abundance', 'CD14+Mo_abundance', 'CD16+Mo_abundance', 'CD4+T_act_abundance', 'CD4+T_naive_abundance', 'CD8+T_cytox_abundance', 'CD8+T_em_abundance', 'CD8+T_te_abundance', 'CD8+T_trans_abundance', 'DC_abundance', 'EC10_CMC-like_abundance', 'EC1_cap_abundance', 'EC2_cap_abundance', 'EC3_cap_abundance', 'EC4_immune_abundance', 'EC5_art_abundance', 'EC6_ven_abundance', 'EC7_endocardial_abundance', 'EC8_ln_abundance', 'FB1_abundance', 'FB2_abundance', 'FB3_abundance', 'FB4_activated_abundance', 'FB5_abundance', 'FB6_abundance', 'ILC_abundance', 'LYVE1+IGF1+MP_abundance', 'LYVE1+MP_cycling_abundance', 'LYVE1+TIMD4+MP_abundance', 'MAIT-like_abundance', 'Mast_abundance', 'Meso_abundance', 'MoMP_abundance', 'NC1_glial_abundance', 'NC2_glial_NGF+_abundance', 'NK_CD16hi_abundance', 'NK_CD56hi_abundance', 'Neut_abundance', 'PC1_vent_abundance', 'PC2_atria_abundance', 'PC3_str_abundance', 'SAN_P_cell_abundance', 'SMC1_basic_abundance', 'SMC2_art_abundance', 'T/NK_cycling_abundance', 'aCM1_abundance', 'aCM2_abundance', 'aCM3_abundance', 'aCM4_abundance', 'AVN_bundle_cell_abundance', 'PC4_CMC-like_abundance', 'vCM1_abundance', 'vCM2_abundance', 'vCM3_stressed_abundance', 'vCM4_abundance', 'vCM5_abundance', 'AVN_P_cell_abundance', 'CD4+T_Tfh_abundance', 'CD4+T_Th1_abundance', 'CD4+T_Th2_abundance', 'CD4+T_reg_abundance', 'NC5_glial_abundance', 'aCM5_abundance', 'Adip4_abundance', 'NC3_glial_abundance', 'NC6_schwann_abundance', 'EC9_FB-like_abundance', 'gdT_abundance', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'donor_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'is_primary_data', 'self_reported_ethnicity_ontology_term_id', 'sex_ontology_term_id', 'suspension_type', 'tissue_ontology_term_id', 'tissue_type', 'cell_type', 'assay', 'disease', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid' #>     var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type' #>     uns: 'cell_type_ontology_term_id_colors', 'citation', 'fullres_xml_metadata', 'organism', 'organism_ontology_term_id', 'schema_reference', 'schema_version', 'spatial', 'spatial_metadata', 'title' #>     obsm: 'X_means_cell_abundance_w_sf', 'X_prop', 'X_q05_cell_abundance_w_sf', 'X_q95_cell_abundance_w_sf', 'X_stds_cell_abundance_w_sf', 'spatial'  lib_id = list(adata_spatial.uns['spatial'].keys())[0] spatial_data = adata_spatial.uns['spatial'][lib_id] print(\"\\nSpatial library:\", lib_id) #>  #> Spatial library: HCAHeartST13228106 print(\"Image keys:\", list(spatial_data.get('images', {}).keys())) #> Image keys: ['fullres', 'hires'] print(\"in_tissue column:\", 'in_tissue' in adata_spatial.obs.columns) #> in_tissue column: True import squidpy as sq import scanpy as sc import pandas as pd  adata_spatial = sc.read_h5ad(\"visium_colon.h5ad\")  # Filter to tissue spots only adata_spatial = adata_spatial[adata_spatial.obs['in_tissue'] == 1].copy()  sc.pp.normalize_total(adata_spatial, target_sum=1e4) sc.pp.log1p(adata_spatial)  adata_spatial.var_names = pd.Index(adata_spatial.var['feature_name'].astype(str).values) adata_spatial.var_names_make_unique()  adata_spatial.write_h5ad(\"visium_normalized.h5ad\")  lib_id = list(adata_spatial.uns['spatial'].keys())[0] sq.pl.spatial_scatter(adata_spatial, color='ACTC1', library_id=lib_id,                       size=1.5, alpha=0.8, use_raw=False, title='ACTC1') Convert(\"visium_normalized.h5ad\", dest = \"h5seurat\", overwrite = TRUE) visium <- LoadH5Seurat(\"visium_normalized.h5seurat\")  # Verify layer mapping: X -> data (log-normalized) cat(\"Layers:\", paste(Layers(visium), collapse = \", \"), \"\\n\") #> Layers: counts, data visium #> An object of class Seurat  #> 32397 features across 3452 samples within 1 assay  #> Active assay: RNA (32397 features, 0 variable features) #>  2 layers present: counts, data #>  5 dimensional reductions calculated: means_cell_abundance_w_sf, prop, q05_cell_abundance_w_sf, q95_cell_abundance_w_sf, stds_cell_abundance_w_sf #>  1 spatial field of view present: HCAHeartST13228106 SpatialFeaturePlot(visium, features = \"ACTC1\", pt.size.factor = 1.6)"},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"data-mapping-reference","dir":"Articles","previous_headings":"","what":"Data Mapping Reference","title":"Conversions: h5Seurat and AnnData","text":"section provides comprehensive mapping tables showing data converted Seurat AnnData formats.","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"core-data-slots","dir":"Articles","previous_headings":"Data Mapping Reference","what":"Core Data Slots","title":"Conversions: h5Seurat and AnnData","text":"Layer mapping h5ad → Seurat conversion: Note: data slot always receives X (typically contains log-normalized values scanpy workflows). h5ad file raw group, X matrix becomes counts. matches scanpy convention adata.X holds processed data adata.raw.X holds raw counts. data structures:","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"metadata-column-mapping","dir":"Articles","previous_headings":"Data Mapping Reference","what":"Metadata Column Mapping","title":"Conversions: h5Seurat and AnnData","text":"Common column name conventions differ Seurat scanpy workflows:","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"column-name-standardization-option","dir":"Articles","previous_headings":"Data Mapping Reference","what":"Column Name Standardization Option","title":"Conversions: h5Seurat and AnnData","text":"default, column names preserved exactly. Use standardize = TRUE automatic name conversion scanpy conventions:","code":"# Preserve original names (default) Convert(\"data.h5Seurat\", dest = \"h5ad\")  # Convert to scanpy naming conventions Convert(\"data.h5Seurat\", dest = \"h5ad\", standardize = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"expression-scale-handling","dir":"Articles","previous_headings":"Data Mapping Reference","what":"Expression Scale Handling","title":"Conversions: h5Seurat and AnnData","text":"Automatic Layer Detection: srtdisk maps layers based h5ad structure: Scales Match: h5ad follows scanpy conventions (X = log-normalized, raw.X = counts), additional processing needed conversion. Scales Differ: X contains raw counts instead normalized data: Warning: normalize Python R - double-normalizes data.","code":"# Normalize after conversion seurat_obj <- NormalizeData(seurat_obj)"},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"indexing-conventions","dir":"Articles","previous_headings":"Data Mapping Reference","what":"Indexing Conventions","title":"Conversions: h5Seurat and AnnData","text":"Python uses 0-based indexing; R uses 1-based. srtdisk handles automatically: Example: Cluster 0 scanpy remains labeled “0” Seurat, internally stored factor level 1.","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"structure-verification","dir":"Articles","previous_headings":"Data Mapping Reference","what":"Structure Verification","title":"Conversions: h5Seurat and AnnData","text":"conversion, verify data integrity: h5ad → Seurat: Seurat → h5ad:","code":"# Check layers and dimensions cat(\"Layers:\", paste(Layers(seurat_obj), collapse = \", \"), \"\\n\") cat(\"Cells:\", ncol(seurat_obj), \"Genes:\", nrow(seurat_obj), \"\\n\")  # Verify data ranges (log-normalized data typically 0-6) cat(\"Data range:\", range(GetAssayData(seurat_obj, layer = \"data\")[1:100, 1:10]), \"\\n\")  # Check metadata preserved head(seurat_obj[[]]) import scanpy as sc adata = sc.read_h5ad(\"converted.h5ad\") print(adata) print(\"obs columns:\", list(adata.obs.columns)) print(\"X range:\", adata.X.min(), \"-\", adata.X.max())"},{"path":"https://mianaz.github.io/srtdisk/articles/convert-anndata.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Conversions: h5Seurat and AnnData","text":"","code":"sessionInfo() #> R version 4.5.2 (2025-10-31) #> Platform: aarch64-apple-darwin20 #> Running under: macOS Tahoe 26.2 #>  #> Matrix products: default #> BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib  #> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1 #>  #> locale: #> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #>  #> time zone: America/Indiana/Indianapolis #> tzcode source: internal #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #>  [1] stxKidney.SeuratData_0.1.0    stxBrain.SeuratData_0.1.2     #>  [3] ssHippo.SeuratData_3.1.4      pbmcref.SeuratData_1.0.0      #>  [5] pbmcMultiome.SeuratData_0.1.4 pbmc3k.SeuratData_3.1.4       #>  [7] panc8.SeuratData_3.0.2        cbmc.SeuratData_3.1.4         #>  [9] SeuratData_0.2.2.9002         srtdisk_0.2.0                 #> [11] Seurat_5.4.0                  SeuratObject_5.3.0            #> [13] sp_2.2-0                      reticulate_1.44.1             #>  #> loaded via a namespace (and not attached): #>   [1] RColorBrewer_1.1-3     jsonlite_2.0.0         magrittr_2.0.4         #>   [4] spatstat.utils_3.2-1   farver_2.1.2           rmarkdown_2.30         #>   [7] fs_1.6.6               ragg_1.5.0             vctrs_0.7.0            #>  [10] ROCR_1.0-11            spatstat.explore_3.7-0 htmltools_0.5.9        #>  [13] sass_0.4.10            sctransform_0.4.3      parallelly_1.46.1      #>  [16] KernSmooth_2.23-26     bslib_0.9.0            htmlwidgets_1.6.4      #>  [19] desc_1.4.3             ica_1.0-3              plyr_1.8.9             #>  [22] plotly_4.11.0          zoo_1.8-15             cachem_1.1.0           #>  [25] igraph_2.2.1           mime_0.13              lifecycle_1.0.5        #>  [28] pkgconfig_2.0.3        Matrix_1.7-4           R6_2.6.1               #>  [31] fastmap_1.2.0          fitdistrplus_1.2-5     future_1.69.0          #>  [34] shiny_1.12.1           digest_0.6.39          patchwork_1.3.2        #>  [37] tensor_1.5.1           RSpectra_0.16-2        irlba_2.3.5.1          #>  [40] textshaping_1.0.4      labeling_0.4.3         progressr_0.18.0       #>  [43] spatstat.sparse_3.1-0  httr_1.4.7             polyclip_1.10-7        #>  [46] abind_1.4-8            compiler_4.5.2         bit64_4.6.0-1          #>  [49] withr_3.0.2            S7_0.2.1               fastDummies_1.7.5      #>  [52] MASS_7.3-65            rappdirs_0.3.4         tools_4.5.2            #>  [55] lmtest_0.9-40          otel_0.2.0             httpuv_1.6.16          #>  [58] future.apply_1.20.1    goftest_1.2-3          glue_1.8.0             #>  [61] nlme_3.1-168           promises_1.5.0         grid_4.5.2             #>  [64] Rtsne_0.17             cluster_2.1.8.1        reshape2_1.4.5         #>  [67] generics_0.1.4         hdf5r_1.3.12           gtable_0.3.6           #>  [70] spatstat.data_3.1-9    tidyr_1.3.2            data.table_1.18.0      #>  [73] spatstat.geom_3.7-0    RcppAnnoy_0.0.23       ggrepel_0.9.6          #>  [76] RANN_2.6.2             pillar_1.11.1          stringr_1.6.0          #>  [79] spam_2.11-3            RcppHNSW_0.6.0         later_1.4.5            #>  [82] splines_4.5.2          dplyr_1.1.4            lattice_0.22-7         #>  [85] survival_3.8-6         bit_4.6.0              deldir_2.0-4           #>  [88] tidyselect_1.2.1       miniUI_0.1.2           pbapply_1.7-4          #>  [91] knitr_1.51             gridExtra_2.3          scattermore_1.2        #>  [94] xfun_0.56              matrixStats_1.5.0      stringi_1.8.7          #>  [97] lazyeval_0.2.2         yaml_2.3.12            evaluate_1.0.5         #> [100] codetools_0.2-20       tibble_3.3.1           cli_3.6.5              #> [103] uwot_0.2.4             xtable_1.8-4           systemfonts_1.3.1      #> [106] jquerylib_0.1.4        dichromat_2.0-0.1      Rcpp_1.1.1             #> [109] globals_0.18.0         spatstat.random_3.4-4  png_0.1-8              #> [112] spatstat.univar_3.1-6  parallel_4.5.2         pkgdown_2.2.0          #> [115] ggplot2_4.0.1          dotCall64_1.2          listenv_0.10.0         #> [118] viridisLite_0.4.2      scales_1.4.0           ggridges_0.5.7         #> [121] purrr_1.2.1            crayon_1.5.3           rlang_1.1.7            #> [124] cowplot_1.2.0"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-load.html","id":"saving-a-dataset","dir":"Articles","previous_headings":"","what":"Saving a dataset","title":"Saving and Loading Data from an h5Seurat File","text":"Saving Seurat object h5Seurat file fairly painless process. assays, dimensional reductions, spatial images, nearest-neighbor graphs automatically saved well extra metadata miscellaneous data, command logs, cell identity classes Seurat object. save Seurat object, need Seurat srtdisk R packages. vignette, ’ll use pbmc3k.final dataset SeuratData - fully processed PBMC dataset clustering, dimensional reductions, nearest-neighbor graphs. seen, dataset multiple components . Saving object simple calling SaveH5Seurat(); minimally, function takes Seurat object nothing else. Optional arguments present specifying filename whether want overwrite preexisting file. process quick results compact -disk file. h5Seurat files HDF5-based can read languages, Python, providing better interoperability Rds files.","code":"library(Seurat) library(srtdisk) library(SeuratData)  # Install pbmc3k if not already installed if (!\"pbmc3k.final\" %in% rownames(InstalledData())) {   InstallData(\"pbmc3k\") }  # Load the processed pbmc3k dataset data(\"pbmc3k.final\", package = \"pbmc3k.SeuratData\") pbmc <- UpdateSeuratObject(pbmc3k.final) pbmc #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  3 layers present: counts, data, scale.data #>  2 dimensional reductions calculated: pca, umap SaveH5Seurat(pbmc, filename = \"pbmc3k.h5Seurat\", overwrite = TRUE) size <- file.size(\"pbmc3k.h5Seurat\") print(structure(size, class = \"object_size\"), units = \"Mb\") #> 52.1 Mb"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-load.html","id":"connecting-to-and-querying-h5seurat-files","dir":"Articles","previous_headings":"","what":"Connecting to and querying h5Seurat files","title":"Saving and Loading Data from an h5Seurat File","text":"Unlike data formats, HDF5 files can connected explored without loading data memory. facilitate , ’ve built h5Seurat object serve interface h5Seurat files R. h5Seurat objects built H5File object hdf5r package. Connecting h5Seurat file simple instantiating h5Seurat object. seen, h5Seurat file structured similarly Seurat object, different HDF5 groups sharing names slots Seurat object. However, ’s difficult glean data present dataset similar calling Seurat object R console. get around , ’ve created index method h5Seurat objects; method creates summary data stored within h5Seurat object. Seurat objects organized around assay data, h5Seurat index showcases data grouped assay. First get breakdown slots filled within assay, followed table dimensional reduction information. table shows bits information (eg. cell embeddings, feature loadings, JackStraw data) present. tables, get list nearest-neighbor graphs spatial image data. way, can see data gets loaded per-assay basis required Seurat. explore h5Seurat file deeper, can use double bracket [[ operator explore various aspects dataset. double bracket [[ operator takes UNIX-style path comprised dataset names. finished exploring h5Seurat file, remember close connection. ’re working file disk directly rather loading memory, need close prevent file corruption. can also open file read-mode (mode = \"r\") help alleviate file corruption, though ’s still good habit close h5Seurat file done working .","code":"hfile <- Connect(\"pbmc3k.h5Seurat\") hfile #> Class: h5Seurat #> Filename: /Users/miana/Documents/GitHub/srtdisk/vignettes/pbmc3k.h5Seurat #> Access type: H5F_ACC_RDONLY #> Attributes: version, project, active.assay #> Listing: #>          name    obj_type dataset.dims dataset.type_class #>  active.ident   H5I_GROUP         <NA>               <NA> #>        assays   H5I_GROUP         <NA>               <NA> #>    cell.names H5I_DATASET         2638         H5T_STRING #>      commands   H5I_GROUP         <NA>               <NA> #>        graphs   H5I_GROUP         <NA>               <NA> #>        images   H5I_GROUP         <NA>               <NA> #>     meta.data   H5I_GROUP         <NA>               <NA> #>          misc   H5I_GROUP         <NA>               <NA> #>     neighbors   H5I_GROUP         <NA>               <NA> #>    reductions   H5I_GROUP         <NA>               <NA> #> < Printed 10, out of 11> hfile$index() #> Data for assay RNA★ (default assay) #>    counts      data    scale.data #>      ✔          ✔          ✔      #> Dimensional reductions: #>         Embeddings  Loadings  Projected  JackStraw  #>  pca:       ✔          ✔          ✖          ✔      #>  umap:      ✔          ✖          ✖          ✖      #> Graphs: #>  ─ RNA_nn #>  ─ RNA_snn hfile[[\"assays\"]] #> Class: H5Group #> Filename: /Users/miana/Documents/GitHub/srtdisk/vignettes/pbmc3k.h5Seurat #> Group: /assays #> Listing: #>  name  obj_type dataset.dims dataset.type_class #>   RNA H5I_GROUP         <NA>               <NA> hfile[[\"assays/RNA\"]] #> Class: H5Group #> Filename: /Users/miana/Documents/GitHub/srtdisk/vignettes/pbmc3k.h5Seurat #> Group: /assays/RNA #> Attributes: key #> Listing: #>               name    obj_type dataset.dims dataset.type_class #>             counts   H5I_GROUP         <NA>               <NA> #>               data   H5I_GROUP         <NA>               <NA> #>           features H5I_DATASET        13714         H5T_STRING #>      meta.features   H5I_GROUP         <NA>               <NA> #>         scale.data H5I_DATASET 13714 x 2638          H5T_FLOAT #>    scaled.features H5I_DATASET        13714         H5T_STRING #>  variable.features H5I_DATASET         2000         H5T_STRING hfile[[\"reductions\"]] #> Class: H5Group #> Filename: /Users/miana/Documents/GitHub/srtdisk/vignettes/pbmc3k.h5Seurat #> Group: /reductions #> Listing: #>  name  obj_type dataset.dims dataset.type_class #>   pca H5I_GROUP         <NA>               <NA> #>  umap H5I_GROUP         <NA>               <NA> hfile[[\"reductions/umap\"]] #> Class: H5Group #> Filename: /Users/miana/Documents/GitHub/srtdisk/vignettes/pbmc3k.h5Seurat #> Group: /reductions/umap #> Attributes: active.assay, key, global #> Listing: #>             name    obj_type dataset.dims dataset.type_class #>  cell.embeddings H5I_DATASET     2638 x 2          H5T_FLOAT #>             misc   H5I_GROUP         <NA>               <NA> hfile$close_all()"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-load.html","id":"loading-datasets","dir":"Articles","previous_headings":"","what":"Loading datasets","title":"Saving and Loading Data from an h5Seurat File","text":"Reading data h5Seurat file simple calling LoadH5Seurat(); default, loads entire object memory. However, situations loading entire Seurat object desirable. , can leverage HDF5 format load parts dataset time. LoadH5Seurat makes use assay association limit data loaded. Seurat objects, dimensional reduction information, nearest-neighbor graphs, spatial image data assay “belong” (see DefaultAssay() Seurat package details). certain assays requested, object associated assays loaded. four main parameters controlling data loading. first assays parameter; parameter controls assays loaded slots assay loaded. simplest level control specifying assays load. dataset, passing assay name load entire assay object assay specified. can also choose slots load; slots available “counts” raw expression data, “data” normalized expression data, “scale.data” scaled expression data. Specifying slots instead assays load desired slots assays requested slots. specifying slots, one either “counts” “data” must specified Seurat object uses slots control dataset dimensionality information. fine-tuned control, assays parameter can also take named list vector, names names assays load values slots load. Finally, passing NULL assays (default behavior) loads assays slots. second main parameters reductions parameter; parameter controls dimensional reductions loaded. dimensional reductions tied assays, data request needs either associated loaded assay marked global loaded (see details ). three special values reductions parameter can take: NULL dimensional reductions can loaded (default behavior), NA global dimensional reductions , FALSE dimensional reduction information. graphs parameter third main parameter; parameter controls nearest-neighbor graphs load. Just like dimensional reduction information, nearest-neighbor graphs tied assays, thus loaded associated assay loaded well. two special values graphs parameter can take: NULL graphs can loaded (default behavior) FALSE nearest-neighbor graphs. final main parameter images parameter; parameter controls spatial image data loaded. spatial image data marked global default, loaded whether associated assays loaded well. images parameter three special values: NULL spatial image data (default), NA global spatial image data (typically NULL), FALSE spatial image data. four parameters, lot customization loading Seurat objects h5Seurat files. example, following load “data” “scale.data” slots “RNA” assay, global dimensional reductions, none nearest neighbor graphs, spatial images. addition, four secondary parameters LoadH5Seurat: meta.data, commands, misc, tools; take simple TRUE/FALSE values control loading cell-level metadata, command logs, miscellaneous information, tool-specific results, respectively. Partial loading datasets excellent way limit memory usage prevent loading massive datasets memory. However, can instances partial dataset loaded, needs expanded additional data h5Seurat file. Instead redoing partial load, can make use AppendData() add additional objects h5Seurat file already-loaded Seurat object. show works, ’ll start loading just “data” slot “RNA” assay, load dimensional reduction information nearest-neighbor graphs. AppendData takes h5Seurat file, Seurat object generated LoadH5Seurat uses four main paramters LoadH5Seurat (assays, reductions, graphs, images). parameters used way LoadH5Seurat one exception: assays can now take FALSE value. passing FALSE, prevent assay information loaded; useful want add bits data Seurat object. example, can choose add global dimensional reductions already existing Seurat object. limits number times AppendData can run h5Seurat file run data present Seurat object. Otherwise, can run multiple times, adding new bits data Seurat object. , fill rest “RNA” assay, load information want perform “full append” (loading bits data Seurat object h5Seurat file), can set four parameters NULL, happens default values parmaters. loads rest Seurat object h5Seurat file memory.","code":"pbmc2 <- LoadH5Seurat(\"pbmc3k.h5Seurat\") pbmc2 #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  3 layers present: counts, data, scale.data #>  2 dimensional reductions calculated: pca, umap pbmc2 <- LoadH5Seurat(\"pbmc3k.h5Seurat\", assays = \"RNA\") pbmc2 #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  3 layers present: counts, data, scale.data #>  2 dimensional reductions calculated: pca, umap pbmc2 <- LoadH5Seurat(\"pbmc3k.h5Seurat\", assays = \"data\") pbmc2 #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  2 layers present: counts, data #>  2 dimensional reductions calculated: pca, umap pbmc2 <- LoadH5Seurat(\"pbmc3k.h5Seurat\", assays = list(\"RNA\" = c(\"data\", \"scale.data\"))) pbmc2 #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  3 layers present: counts, data, scale.data #>  2 dimensional reductions calculated: pca, umap pbmc2 <- LoadH5Seurat(\"pbmc3k.h5Seurat\", assays = \"RNA\", reductions = \"pca\") pbmc2 #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  3 layers present: counts, data, scale.data #>  1 dimensional reduction calculated: pca pbmc2 <- LoadH5Seurat(\"pbmc3k.h5Seurat\", assays = list(\"RNA\" = c(\"data\", \"scale.data\")), reductions = NA, graphs = FALSE, images = FALSE) pbmc2 #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  3 layers present: counts, data, scale.data #>  1 dimensional reduction calculated: umap pbmc2 <- LoadH5Seurat(\"pbmc3k.h5Seurat\", assays = c(\"RNA\" = \"data\"), reductions = FALSE, graphs = FALSE, images = FALSE) pbmc2 #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  2 layers present: counts, data pbmc2 <- AppendData(\"pbmc3k.h5Seurat\", pbmc2, assays = FALSE, reductions = NA, graphs = FALSE, images = FALSE) pbmc2 #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  2 layers present: counts, data #>  1 dimensional reduction calculated: umap pbmc2 <- AppendData(\"pbmc3k.h5Seurat\", pbmc2, assays = \"RNA\", reductions = FALSE, graphs = FALSE, images = FALSE) pbmc2 #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  2 layers present: counts, data #>  1 dimensional reduction calculated: umap pbmc2 <- AppendData(\"pbmc3k.h5Seurat\", pbmc2) pbmc2 #> An object of class Seurat  #> 13714 features across 2638 samples within 1 assay  #> Active assay: RNA (13714 features, 2000 variable features) #>  2 layers present: counts, data #>  2 dimensional reductions calculated: umap, pca"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-load.html","id":"working-with-spatial-data","dir":"Articles","previous_headings":"","what":"Working with Spatial Data","title":"Saving and Loading Data from an h5Seurat File","text":"spatial transcriptomics data, can use stxBrain dataset SeuratData: Save reload demonstrate h5Seurat spatial data:","code":"library(SeuratData)  # Install stxBrain if not already installed if (!\"stxBrain\" %in% rownames(InstalledData())) {   InstallData(\"stxBrain\") }  # Load anterior1 section brain <- UpdateSeuratObject(LoadData(\"stxBrain\", type = \"anterior1\")) brain #> An object of class Seurat  #> 31053 features across 2696 samples within 1 assay  #> Active assay: Spatial (31053 features, 0 variable features) #>  1 layer present: counts #>  1 spatial field of view present: anterior1 SaveH5Seurat(brain, filename = \"stxBrain.h5Seurat\", overwrite = TRUE)  # Reload brain2 <- LoadH5Seurat(\"stxBrain.h5Seurat\")  # Verify spatial images are preserved cat(\"Original images:\", Images(brain), \"\\n\") #> Original images: anterior1 cat(\"Reloaded images:\", Images(brain2), \"\\n\") #> Reloaded images: anterior1"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-load.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Saving and Loading Data from an h5Seurat File","text":"","code":"sessionInfo() #> R version 4.5.2 (2025-10-31) #> Platform: aarch64-apple-darwin20 #> Running under: macOS Tahoe 26.2 #>  #> Matrix products: default #> BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib  #> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1 #>  #> locale: #> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #>  #> time zone: America/Indiana/Indianapolis #> tzcode source: internal #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #>  [1] stxKidney.SeuratData_0.1.0    stxBrain.SeuratData_0.1.2     #>  [3] ssHippo.SeuratData_3.1.4      pbmcref.SeuratData_1.0.0      #>  [5] pbmcMultiome.SeuratData_0.1.4 pbmc3k.SeuratData_3.1.4       #>  [7] panc8.SeuratData_3.0.2        cbmc.SeuratData_3.1.4         #>  [9] SeuratData_0.2.2.9002         srtdisk_0.2.0                 #> [11] Seurat_5.4.0                  SeuratObject_5.3.0            #> [13] sp_2.2-0                      #>  #> loaded via a namespace (and not attached): #>   [1] RColorBrewer_1.1-3     jsonlite_2.0.0         magrittr_2.0.4         #>   [4] spatstat.utils_3.2-1   farver_2.1.2           rmarkdown_2.30         #>   [7] fs_1.6.6               ragg_1.5.0             vctrs_0.7.0            #>  [10] ROCR_1.0-11            spatstat.explore_3.7-0 htmltools_0.5.9        #>  [13] sass_0.4.10            sctransform_0.4.3      parallelly_1.46.1      #>  [16] KernSmooth_2.23-26     bslib_0.9.0            htmlwidgets_1.6.4      #>  [19] desc_1.4.3             ica_1.0-3              plyr_1.8.9             #>  [22] plotly_4.11.0          zoo_1.8-15             cachem_1.1.0           #>  [25] igraph_2.2.1           mime_0.13              lifecycle_1.0.5        #>  [28] pkgconfig_2.0.3        Matrix_1.7-4           R6_2.6.1               #>  [31] fastmap_1.2.0          fitdistrplus_1.2-5     future_1.69.0          #>  [34] shiny_1.12.1           digest_0.6.39          patchwork_1.3.2        #>  [37] tensor_1.5.1           RSpectra_0.16-2        irlba_2.3.5.1          #>  [40] textshaping_1.0.4      progressr_0.18.0       spatstat.sparse_3.1-0  #>  [43] httr_1.4.7             polyclip_1.10-7        abind_1.4-8            #>  [46] compiler_4.5.2         bit64_4.6.0-1          S7_0.2.1               #>  [49] fastDummies_1.7.5      MASS_7.3-65            rappdirs_0.3.4         #>  [52] tools_4.5.2            lmtest_0.9-40          otel_0.2.0             #>  [55] httpuv_1.6.16          future.apply_1.20.1    goftest_1.2-3          #>  [58] glue_1.8.0             nlme_3.1-168           promises_1.5.0         #>  [61] grid_4.5.2             Rtsne_0.17             cluster_2.1.8.1        #>  [64] reshape2_1.4.5         generics_0.1.4         hdf5r_1.3.12           #>  [67] gtable_0.3.6           spatstat.data_3.1-9    tidyr_1.3.2            #>  [70] data.table_1.18.0      spatstat.geom_3.7-0    RcppAnnoy_0.0.23       #>  [73] ggrepel_0.9.6          RANN_2.6.2             pillar_1.11.1          #>  [76] stringr_1.6.0          spam_2.11-3            RcppHNSW_0.6.0         #>  [79] later_1.4.5            splines_4.5.2          dplyr_1.1.4            #>  [82] lattice_0.22-7         survival_3.8-6         bit_4.6.0              #>  [85] deldir_2.0-4           tidyselect_1.2.1       miniUI_0.1.2           #>  [88] pbapply_1.7-4          knitr_1.51             gridExtra_2.3          #>  [91] scattermore_1.2        xfun_0.56              matrixStats_1.5.0      #>  [94] stringi_1.8.7          lazyeval_0.2.2         yaml_2.3.12            #>  [97] evaluate_1.0.5         codetools_0.2-20       tibble_3.3.1           #> [100] cli_3.6.5              uwot_0.2.4             xtable_1.8-4           #> [103] reticulate_1.44.1      systemfonts_1.3.1      jquerylib_0.1.4        #> [106] dichromat_2.0-0.1      Rcpp_1.1.1             globals_0.18.0         #> [109] spatstat.random_3.4-4  png_0.1-8              spatstat.univar_3.1-6  #> [112] parallel_4.5.2         pkgdown_2.2.0          ggplot2_4.0.1          #> [115] dotCall64_1.2          listenv_0.10.0         viridisLite_0.4.2      #> [118] scales_1.4.0           ggridges_0.5.7         purrr_1.2.1            #> [121] crayon_1.5.3           rlang_1.1.7            cowplot_1.2.0"},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"required-attributes","dir":"Articles","previous_headings":"Overall File Structure","what":"Required Attributes","title":"h5Seurat File Format Specification","text":"three required top-level HDF5 attributes: “project”, “active.assay”, “version”. must single character. “project” attribute corresponds project value Seurat object; “active.assay” attribute name default assay must present “assays” group. “version” corresponds version Seurat h5Seurat file based .","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"top-level-datasets-and-groups","dir":"Articles","previous_headings":"Overall File Structure","what":"Top-Level Datasets and Groups","title":"h5Seurat File Format Specification","text":"two required top-level HDF5 datasets: “cell.names” “meta.data”. “cell.names” dataset one-dimensional character dataset, length equal number cells present data. Cell names stored anywhere else h5Seurat file. “meta.data” dataset contains cell-level metadata. stored either HDF5 dataset group, depending contents meta data. See data frame representation details.","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"assay-expression-data","dir":"Articles","previous_headings":"","what":"Assay Expression Data","title":"h5Seurat File Format Specification","text":"Assay objects stored top-level group “assays”; assay stored group within “assays” group. Within assay group, must dataset named “features” either dataset group named “data”; “features” dataset must one-dimensional character dataset length equal number total features within assay. “data” entry matrix, dimensions mfeaturesxncellsm_{features} x n_{cells}; entry may either dataset, “data” dense matrix, group, “data” sparse matrix. Assay groups must also attribute named “key”; single character value. Assay groups may also following optional groups datasets: “counts”: either dense sparse matrix; must dimesions “data” “scale.data”: dense matrix; “scale.data” present, one-dimensional character dataset must also present. “scale.data” matrix must dimensions mscaledfeaturesxncellsm_{scaled features} x n_{cells} “meta.features”: data frame number rows values present “features” “variable.features”: one-dimensional character dataset “misc”: list Subclasses Assay objects must also follow rules custom S4 classes. Seurat V5 Assay5 Support: implementation fully supports Seurat v5 Assay5 objects. saving h5Seurat, Assay5 objects automatically converted storage format described , layers (counts, data, scale.data) preserved separate matrices. loading, format compatible legacy Assay modern Assay5 objects.","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"dimensional-reductions","dir":"Articles","previous_headings":"","what":"Dimensional Reductions","title":"h5Seurat File Format Specification","text":"Dimensional reduction information stored top-level group “reductions”; dimensional reduction stored group within “reductions” group. Within dimensional reduction group, three required attributes: “active.assay”, “key”, “global”; “active.assay” must one character values value name assay, “key” must single character value, “global” must single logical value. addition, must also dataset named “cell.embeddings” representing dense matrix. matrix must number rows cells present h5Seurat file. Dimensional reduction groups may also following optional groups datasets: “feature.loadings”: … “feature.loadings.projected”: … “misc”: list “jackstraw”: custom S4 group","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"nearest-neighbor-graphs","dir":"Articles","previous_headings":"","what":"Nearest-Neighbor Graphs","title":"h5Seurat File Format Specification","text":"Nearest-neighbor graphs stored top-level group “graphs”; graph stored group within “graphs” group. Graph names become graph group names. Graphs stored sparse matrices additional HDF5 attribute: “assay.used”. HDF5 attribute single character value.","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"spatial-image-data","dir":"Articles","previous_headings":"","what":"Spatial Image Data","title":"h5Seurat File Format Specification","text":"Spatial image data stored top-level group “images”; image stored group within “images” group. Actual structure image group dependent structure spatial image data. However, follows rules custom S4 classes. Note: spatial images supported objects generated version Seurat spatial support. Currently, restricted version 3.1.5.9900 higher.","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"miscellaneous-information-and-tool-specific-results","dir":"Articles","previous_headings":"","what":"Miscellaneous Information and Tool-Specific Results","title":"h5Seurat File Format Specification","text":"Miscellaneous information stored top-level group “misc”; group follows runs lists. “misc” group required present, required filled. Tool-specific results stored top-level group “tools”; group follows runs lists. “tools” group required present, required filled.","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"common-data-structures","dir":"Articles","previous_headings":"","what":"Common Data Structures","title":"h5Seurat File Format Specification","text":"data types found commonly throughout Seurat objects","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"character-representation","dir":"Articles","previous_headings":"Common Data Structures","what":"Character Representation","title":"h5Seurat File Format Specification","text":"character values (strings languages) encoding variable-length UTF-8 strings; applies HDF5 datasets (including standalone string datasets well parts compound datasets) HDF5 attributes.","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"dense-matrix-representation","dir":"Articles","previous_headings":"Common Data Structures","what":"Dense Matrix Representation","title":"h5Seurat File Format Specification","text":"Dense matrices stored two-dimensional dataset type. Datasets written column-major order. column-major implementations (eg. R, Fortran), dataset dimensions -disk dimensions -memory (eg. mdiskrowxndiskcol∼mmemrowxnmemcolm_{diskrow} x n_{diskcol} \\sim m_{memrow} x n_{memcol}). row-major implmentations (eg. C/C++, Python), dataset dimensions -disk appear transposed dimensions -memory (eg. mdiskrowxndiskcol∼nmemrowxmmemcolm_{diskrow} x n_{diskcol} \\sim n_{memrow} x m_{memcol}); row-major implmemetnations transpose datasets prior reading writing data.","code":"#>      [,1] [,2] [,3] [,4] #> [1,]    0    0    0    1 #> [2,]    0    1    1    1 #> [3,]    1    1    0    0 #> HDF5 Dataset: densemat #>   Dimensions: 3 x 4 #>      [,1] [,2] [,3] [,4] #> [1,]    0    0    0    1 #> [2,]    0    1    1    1 #> [3,]    1    1    0    0"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"sparse-matrix-representation","dir":"Articles","previous_headings":"Common Data Structures","what":"Sparse Matrix Representation","title":"h5Seurat File Format Specification","text":"Sparse matrices stored HDF5 group three datasets: “indices”, “indptr”, “data”; “indices” “data” datasets must length. “data” represents non-zero element matrix. “indices” represents 00-based row numbers value “data” “indptr” represents points “data” new column started. dataset 00-based ncolumns+1n_{columns} + 1 length. “indices”, “indptr”, “data” datasets correspond “”, “p”, “x” slots dgCMatrix, respectively. may optionally HDF5 attribute called “dims”; attribute two integer values corresponding number rows number columns, order, sparse matrix.","code":"#> 3 x 4 sparse Matrix of class \"dgCMatrix\" #>              #> [1,] . . . 1 #> [2,] . 1 1 1 #> [3,] 1 1 . . #> HDF5 Group: sparsemat #>   Members: data, indices, indptr #>  #> HDF5 Dataset: sparsemat/indices #>   Length: 6 #> [1] 2 1 2 1 0 1 #>  #> HDF5 Dataset: sparsemat/data #>   Length: 6 #> [1] 1 1 1 1 1 1 #> HDF5 Dataset: sparsemat/indptr #>   Length: 5 #> [1] 0 1 3 4 6 #> [1] 3 4"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"factor-representation","dir":"Articles","previous_headings":"Common Data Structures","what":"Factor Representation","title":"h5Seurat File Format Specification","text":"Factors stored HDF5 group two datasets: “levels” “values” “levels” dataset character dataset one entry per level “values” dataset integer dataset one entry per value original factor. integers correspond factor level R number unique entries “values” exceed number unique entries “levels”","code":"#> [1] g1 g2 g1 g1 g2 #> Levels: g1 g2 #> HDF5 Group: factor #>   Members: levels, values #> HDF5 Dataset: factor/levels #>   Length: 2 #> [1] \"g1\" \"g2\" #> HDF5 Dataset: factor/values #>   Length: 5 #> [1] 1 2 1 1 2"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"logical-representation","dir":"Articles","previous_headings":"Common Data Structures","what":"Logical Representation","title":"h5Seurat File Format Specification","text":"Logical values (booleans languages) encoded integers following manner: FALSE encoded 0, TRUE encoded 1, NA encoded 2 optional HDF5 attribute named “s3class” value “logical” allowed enforce reading dataset logical values. HDF5 attribute single character value. Unlike languages, logicals (booleans) can take one three values: TRUE, FALSE, NA; , extra integer value needed handle additional logical value. Typically, values stored enums mappings logical representation integer value. However, implementations HDF5 support enums thus lose logical representation. Since mappings lost, logicals stored integers instead.","code":"#> [1]  TRUE FALSE    NA #> HDF5 Dataset: logicals #>   Length: 3 #> [1] 1 0 2"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"data-frame-representation","dir":"Articles","previous_headings":"Common Data Structures","what":"Data Frame Representation","title":"h5Seurat File Format Specification","text":"two ways storing data frames h5Seurat files: datasets groups. Data frame groups required data frames contain factors; factors present, data frames can stored either type.","code":""},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"data-frame-datasets","dir":"Articles","previous_headings":"Common Data Structures > Data Frame Representation","what":"Data Frame Datasets","title":"h5Seurat File Format Specification","text":"Data frames stored datasets one-dimensional compound dataset. single dimension equal number observations (number rows) data frame. data type compound dataset must adhere requirements standard datasets (eg. character encodings, logical mapping, etc). compound labels correspond data frame column names. Row names stored dataset , may stored elsewhere h5Seurat file, typically named dataset_name.row.names; optional HDF5 attribute called “logicals” containing names logical columns allowed. attribute consists character values.","code":"#>    x y #> 1 g1 1 #> 2 g1 2 #> 3 g2 3 #> 4 g1 4 #> 5 g2 5 #> HDF5 Dataset: dfdataset (compound) #>   Length: 5 #>    x y #> 1 g1 1 #> 2 g1 2 #> 3 g2 3 #> 4 g1 4 #> 5 g2 5"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"data-frame-groups","dir":"Articles","previous_headings":"Common Data Structures > Data Frame Representation","what":"Data Frame Groups","title":"h5Seurat File Format Specification","text":"Data frames stored groups used factors present data frame. Within data frame group, one dataset group per column. Columns factors stored groups columns stored one-dimensional datasets. dataset within group must adhere requirements standard datasets (eg. character encodings, logical mapping, etc). names datasets within group correspond data frame column names Data frame row names may stored dataset called “row.names” within group; dataset one-dimensional character dataset. two optional attributes allowed: “colnames” “logicals”; “colnames” attribute contains column names order present -memory data frame character values. used control column order reading data frame back memory. Note, “colnames” attribute need contain name every dataset. “logicals” attribute contains names logical columns; attribute consist character values.","code":"#> HDF5 Group: dfgroup #>   Members: _index, x, y"},{"path":"https://mianaz.github.io/srtdisk/articles/h5Seurat-spec.html","id":"list-and-custom-class-representation","dir":"Articles","previous_headings":"Common Data Structures","what":"List and Custom Class Representation","title":"h5Seurat File Format Specification","text":"Lists stored HDF5 groups. entry list must named; names serve names datasets groups within list group. List values stored HDF5 datasets groups, depending R object type. example, list within list stored group within first group. Custom classes stored lists special HDF5 attribute. S3 classes stored attribute “s3class”, value equal class object. attribute variable-length character value. Custom S4 classes also stored lists entry slot S4 class. S4 class groups attribute named “s4class”; attribute single-length character storing name class package defines class form package:class (eg. Signac:ChromatinAssay); custom S4 classes defined Seurat package can named just class object.","code":"#> $a #> [1] 1 2 3 #>  #> $b #> $b$b1 #> [1] \"hello\" #>  #> $b$b2 #> [1] \"tomato\" \"potato\" #> HDF5 Group: list #>   Members: a, b #>  #> HDF5 Group: list/b #>   Members: b1, b2"},{"path":"https://mianaz.github.io/srtdisk/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Miana Z. Author, maintainer. Paul Hoffman. Author. Rahul Satija. Author.","code":""},{"path":"https://mianaz.github.io/srtdisk/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Z M, Hoffman P, Satija R (2026). srtdisk: Extended HDF5-Based Single Cell File Format Support. R package version 0.2.0, https://mianaz.github.io/srtdisk/.","code":"@Manual{,   title = {srtdisk: Extended HDF5-Based Single Cell File Format Support},   author = {Miana Z and Paul Hoffman and Rahul Satija},   year = {2026},   note = {R package version 0.2.0},   url = {https://mianaz.github.io/srtdisk/}, }"},{"path":"https://mianaz.github.io/srtdisk/index.html","id":"srtdisk-v020","dir":"","previous_headings":"","what":"Extended HDF5-Based Single Cell File Format Support","title":"Extended HDF5-Based Single Cell File Format Support","text":"Extended implementation SeuratDisk Seurat v5 enhanced support HDF5-based single cell file formats. h5Seurat file format specifically designed storage analysis multi-modal single-cell spatially-resolved expression experiments, example, CITE-seq 10X Visium technologies. holds molecular information associated metadata, including (example) nearest-neighbor graphs, dimensional reduction information, spatial coordinates image data, cluster labels. also support rapid -disk conversion h5Seurat AnnData objects, goal enhancing interoperability Seurat Scanpy. version includes Seurat v5 Assay5 compatibility improved spatial data handling.","code":""},{"path":[]},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/index.html","id":"seurat-to-h5ad-two-step","dir":"","previous_headings":"Quick Start","what":"Seurat to h5ad (Two-step)","title":"Extended HDF5-Based Single Cell File Format Support","text":"","code":"library(Seurat) library(srtdisk) library(SeuratData)  data(\"pbmc3k.final\", package = \"pbmc3k.SeuratData\") pbmc <- UpdateSeuratObject(pbmc3k.final)  # Step 1: Save as h5Seurat SaveH5Seurat(pbmc, filename = \"pbmc3k.h5Seurat\", overwrite = TRUE)  # Step 2: Convert to h5ad Convert(\"pbmc3k.h5Seurat\", dest = \"h5ad\", overwrite = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/index.html","id":"seurat-to-h5ad-one-step","dir":"","previous_headings":"Quick Start","what":"Seurat to h5ad (One-step)","title":"Extended HDF5-Based Single Cell File Format Support","text":"","code":"# Direct conversion using wrapper function SeuratToH5AD(pbmc, filename = \"pbmc3k_direct.h5ad\", overwrite = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/index.html","id":"h5ad-to-seurat","dir":"","previous_headings":"Quick Start","what":"h5ad to Seurat","title":"Extended HDF5-Based Single Cell File Format Support","text":"","code":"# Using bundled CRC sample h5ad_path <- system.file(\"testdata\", \"crc_sample.h5ad\", package = \"srtdisk\") Convert(h5ad_path, dest = \"h5seurat\", overwrite = TRUE) crc <- LoadH5Seurat(\"crc_sample.h5seurat\")"},{"path":"https://mianaz.github.io/srtdisk/index.html","id":"multi-assay-eg-cite-seq","dir":"","previous_headings":"Quick Start","what":"Multi-assay (e.g. CITE-seq)","title":"Extended HDF5-Based Single Cell File Format Support","text":"","code":"# Note: Converts one assay at a time library(SeuratData) InstallData(\"cbmc\") data(\"cbmc\", package = \"cbmc.SeuratData\") SeuratToH5AD(cbmc, filename = \"cbmc_rna.h5ad\", assay = \"RNA\", overwrite = TRUE) SeuratToH5AD(cbmc, filename = \"cbmc_adt.h5ad\", assay = \"ADT\", overwrite = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/index.html","id":"spatial-data-conversion","dir":"","previous_headings":"Quick Start","what":"Spatial Data Conversion","title":"Extended HDF5-Based Single Cell File Format Support","text":"","code":"library(SeuratData) InstallData(\"stxBrain\") brain <- UpdateSeuratObject(LoadData(\"stxBrain\", type = \"anterior1\")) SeuratToH5AD(brain, filename = \"brain_spatial.h5ad\", overwrite = TRUE)"},{"path":[]},{"path":[]},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/index.html","id":"conversion-options","dir":"","previous_headings":"Function Reference","what":"Conversion Options","title":"Extended HDF5-Based Single Cell File Format Support","text":"detailed documentation, see vignettes: - Conversions: h5Seurat AnnData - Saving Loading h5Seurat Files - h5Seurat File Format Specification","code":""},{"path":"https://mianaz.github.io/srtdisk/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Extended HDF5-Based Single Cell File Format Support","text":"srtdisk currently available CRAN. can install GitHub :","code":"if (!requireNamespace(\"remotes\", quietly = TRUE)) {   install.packages(\"remotes\") } remotes::install_github(\"mianaz/srtdisk\")"},{"path":"https://mianaz.github.io/srtdisk/index.html","id":"dependencies","dir":"","previous_headings":"","what":"Dependencies","title":"Extended HDF5-Based Single Cell File Format Support","text":"srtdisk depends following non-standard packages:","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/AppendData.html","id":null,"dir":"Reference","previous_headings":"","what":"Append data from an h5Seurat file to a preexisting Seurat object — AppendData","title":"Append data from an h5Seurat file to a preexisting Seurat object — AppendData","text":"Append data h5Seurat file preexisting Seurat object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/AppendData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Append data from an h5Seurat file to a preexisting Seurat object — AppendData","text":"","code":"AppendData(   file,   object,   assays = NULL,   reductions = NULL,   graphs = NULL,   images = NULL,   extras = \"commands\",   overwrite = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'character' AppendData(   file,   object,   assays = NULL,   reductions = NULL,   graphs = NULL,   images = NULL,   extras = \"commands\",   overwrite = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'H5File' AppendData(   file,   object,   assays = NULL,   reductions = NULL,   graphs = NULL,   images = NULL,   extras = \"commands\",   overwrite = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'h5Seurat' AppendData(   file,   object,   assays = NULL,   reductions = NULL,   graphs = NULL,   images = NULL,   extras = \"commands\",   overwrite = FALSE,   verbose = TRUE,   ... )"},{"path":"https://mianaz.github.io/srtdisk/reference/AppendData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Append data from an h5Seurat file to a preexisting Seurat object — AppendData","text":"file Path h5Seurat file open h5Seurat object object Seurat object append data assays One : character vector names assays character vector one counts, data,   scale.data describing slots assays load named list entry either name assay vector   describing slots (described ) take assay NULL assays FALSE assays reductions One : character vector names reductions NULL reductions NA global reductions FALSE reductions Note: reductions associated assay loaded assays marked global loaded graphs One : character vector names graphs NULL graphs FALSE graphs Note: graphs associated assay loaded assays loaded images One : character vector names images NULL images NA global images FALSE images extras Extra information load; supports combination following values: “commands” Load command logs. overwrite = TRUE,  replaces existing command logs overwrite Overwrite existing data object data file verbose Show progress updates ... Arguments passed methods","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/AppendData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Append data from an h5Seurat file to a preexisting Seurat object — AppendData","text":"object extra data requested","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/AssembleObject.html","id":null,"dir":"Reference","previous_headings":"","what":"Assemble an object from an h5Seurat file — AssembleObject","title":"Assemble an object from an h5Seurat file — AssembleObject","text":"Assemble object h5Seurat file","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/AssembleObject.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assemble an object from an h5Seurat file — AssembleObject","text":"","code":"AssembleAssay(assay, file, slots = NULL, verbose = TRUE)  AssembleDimReduc(reduction, file, verbose = TRUE)  AssembleGraph(graph, file, verbose = TRUE)  AssembleImage(image, file, verbose = TRUE)  AssembleNeighbor(neighbor, file, verbose = TRUE)  AssembleSeuratCommand(cmd, file, verbose = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/AssembleObject.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assemble an object from an h5Seurat file — AssembleObject","text":"assay, reduction, graph, image, neighbor, cmd Name assay, reduction, graph, image, neighbor, command load file connected h5Seurat file pull data slots Optional vector assay slots load, defaults slots present assay verbose Show progress updates","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/AssembleObject.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assemble an object from an h5Seurat file — AssembleObject","text":"AssembleAssay: Assay object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/BasicWrite.html","id":null,"dir":"Reference","previous_headings":"","what":"Write lists and other data to an HDF5 dataset — BasicWrite","title":"Write lists and other data to an HDF5 dataset — BasicWrite","text":"Write lists data HDF5 dataset","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/BasicWrite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write lists and other data to an HDF5 dataset — BasicWrite","text":"","code":"BasicWrite(x, name, hgroup, verbose = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/BasicWrite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write lists and other data to an HDF5 dataset — BasicWrite","text":"x object name Name save data hgroup HDF5 file group (H5File H5Group objects hdf5r) verbose Show progress updates","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/BasicWrite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write lists and other data to an HDF5 dataset — BasicWrite","text":"Invisibly returns NULL","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/BoolToInt.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a logical to an integer — BoolToInt","title":"Convert a logical to an integer — BoolToInt","text":"Unlike programming languages, R three possible logical (boolean) values: TRUE, FALSE, NA; moreover, NA value representations data types, NA_integer_, NA_real_, NA_character_. Simply writing logical values HDF5 file cause issues trying read data another language, Python. encode three logical values languages, can encode logicals integers: FALSE becomes 0L TRUE becomes 1L NA becomes 2L encoding scheme allows languages handle NAs manner preserving three logicals R","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/BoolToInt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a logical to an integer — BoolToInt","text":"","code":"BoolToInt(x)"},{"path":"https://mianaz.github.io/srtdisk/reference/BoolToInt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a logical to an integer — BoolToInt","text":"x logical vector","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/BoolToInt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a logical to an integer — BoolToInt","text":"integer vector","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/BoolToInt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a logical to an integer — BoolToInt","text":"","code":"# \\donttest{ srtdisk:::BoolToInt(x = c(TRUE, FALSE, NA)) #> [1] 1 0 2 # }"},{"path":"https://mianaz.github.io/srtdisk/reference/CheckMatrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that a dataset is a proper loom matrix — CheckMatrix","title":"Check that a dataset is a proper loom matrix — CheckMatrix","text":"Check dataset proper loom matrix","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/CheckMatrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that a dataset is a proper loom matrix — CheckMatrix","text":"","code":"CheckMatrix(lfile, name, dims = NULL)"},{"path":"https://mianaz.github.io/srtdisk/reference/CheckMatrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that a dataset is a proper loom matrix — CheckMatrix","text":"lfile loom H5File object name Name matrix check dims provided, ensure lfile[[name]] dimensions; two-dimensional numeric vector ncells/ncol first value nfeature/nrow second","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/CheckMatrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that a dataset is a proper loom matrix — CheckMatrix","text":"checks pass successfully, invisibly returns name","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ChunkPoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate chunk points — ChunkPoints","title":"Generate chunk points — ChunkPoints","text":"Generate chunk points","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ChunkPoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate chunk points — ChunkPoints","text":"","code":"ChunkPoints(dsize, csize)"},{"path":"https://mianaz.github.io/srtdisk/reference/ChunkPoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate chunk points — ChunkPoints","text":"dsize Size data chunked csize Size chunk; NA, assumes single chunk","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ChunkPoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate chunk points — ChunkPoints","text":"matrix row chunk, column 1 start points, column 2 end points","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ChunkPoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate chunk points — ChunkPoints","text":"","code":"# \\donttest{ srtdisk:::ChunkPoints(100, 3) #>       start end #>  [1,]     1   3 #>  [2,]     4   6 #>  [3,]     7   9 #>  [4,]    10  12 #>  [5,]    13  15 #>  [6,]    16  18 #>  [7,]    19  21 #>  [8,]    22  24 #>  [9,]    25  27 #> [10,]    28  30 #> [11,]    31  33 #> [12,]    34  36 #> [13,]    37  39 #> [14,]    40  42 #> [15,]    43  45 #> [16,]    46  48 #> [17,]    49  51 #> [18,]    52  54 #> [19,]    55  57 #> [20,]    58  60 #> [21,]    61  63 #> [22,]    64  66 #> [23,]    67  69 #> [24,]    70  72 #> [25,]    73  75 #> [26,]    76  78 #> [27,]    79  81 #> [28,]    82  84 #> [29,]    85  87 #> [30,]    88  90 #> [31,]    91  93 #> [32,]    94  96 #> [33,]    97  99 #> [34,]   100 100 srtdisk:::ChunkPoints(100, NA) #>      start end #> [1,]     1 100 # }"},{"path":"https://mianaz.github.io/srtdisk/reference/ClosestVersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the closest version — ClosestVersion","title":"Find the closest version — ClosestVersion","text":"API changes happen set versions, knowing current running version relates versions introducing API changes important. ClosestVersion approximages “rounding ” (eg. determine minimum version new API addition) “rounding ” (eg. determine maximum version API deletion) semantic versions.","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ClosestVersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the closest version — ClosestVersion","text":"","code":"ClosestVersion(   query,   targets,   direction = c(\"min\", \"max\"),   inclusive = direction == \"min\" )"},{"path":"https://mianaz.github.io/srtdisk/reference/ClosestVersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the closest version — ClosestVersion","text":"query query version (character numeric_version) targets vector target versions (character numeric_version) direction way check closest version? Choose : min Closest version less equal query max Closest version greater equal query inclusive Perform inclusive comparison (eg. >= <= versus > <) “rounding”","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ClosestVersion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the closest version — ClosestVersion","text":"version targets closest query character vector","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/ClosestVersion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the closest version — ClosestVersion","text":"","code":"# \\donttest{ srtdisk:::ClosestVersion('3.1.0', targets = c('3.0.0', '1.4.9', '4.3.2')) #> [1] \"3.0.0\" srtdisk:::ClosestVersion('3.1.0', targets = c('3.0.0', '1.4.9', '4.3.2'), direction = 'max') #> [1] \"4.3.2\" # }"},{"path":"https://mianaz.github.io/srtdisk/reference/CompoundToGroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an HDF5 compound dataset to a group — CompoundToGroup","title":"Convert an HDF5 compound dataset to a group — CompoundToGroup","text":"Convert HDF5 compound dataset group","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/CompoundToGroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an HDF5 compound dataset to a group — CompoundToGroup","text":"","code":"CompoundToGroup(src, dst, dname, order, index = NULL, name_map_fn = NULL)"},{"path":"https://mianaz.github.io/srtdisk/reference/CompoundToGroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an HDF5 compound dataset to a group — CompoundToGroup","text":"src HDF5 dataset (H5D) type H5T_COMPOUND dst HDF5 file (H5File) group (H5Group) dname Name group dst order Column order specification index Integer values values pull; defaults values name_map_fn Optional function map compound field names","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/CompoundToGroup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an HDF5 compound dataset to a group — CompoundToGroup","text":"Invisibly returns NULL","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Connect.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect to a single-cell HDF5 dataset — Connect","title":"Connect to a single-cell HDF5 dataset — Connect","text":"Connect single-cell HDF5 dataset","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Connect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Connect to a single-cell HDF5 dataset — Connect","text":"","code":"Connect(filename, type = NULL, mode = c(\"r\", \"r+\"), force = FALSE)"},{"path":"https://mianaz.github.io/srtdisk/reference/Connect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Connect to a single-cell HDF5 dataset — Connect","text":"filename Name -disk file type Type single-cell dataset connect ; choose : h5seurat Leave NULL guess type file extension mode Mode connect data ; choose : r Open existing dataset read-mode r+ Open existing dataset read/write mode force Force connection validation steps fail; returns H5File object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Connect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect to a single-cell HDF5 dataset — Connect","text":"object class type, opened mode mode","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an on-disk single-cell dataset to another format — Convert","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"HDF5-based single-cell datasets can converted one format another using minimal memory. Details conversion formats implemented provided ","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"","code":"Convert(source, dest, assay, overwrite = FALSE, verbose = TRUE, standardize = FALSE, ...)  # S3 method for class 'character' Convert(source, dest, assay, overwrite = FALSE, verbose = TRUE, standardize = FALSE, ...)  # S3 method for class 'H5File' Convert(   source,   dest = \"h5seurat\",   assay = \"RNA\",   overwrite = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'h5Seurat' Convert(   source,   dest = \"h5ad\",   assay = DefaultAssay(object = source),   overwrite = FALSE,   verbose = TRUE,   standardize = FALSE,   ... )"},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"source Source dataset dest Name destination dataset assay Converting h5Seurat: name assay write ; converting h5Seurat: name store assay data overwrite Overwrite existing dest verbose Show progress updates standardize Logical; TRUE, convert Seurat-style metadata column names scanpy/AnnData conventions converting h5ad format. example, nCount_RNA becomes n_counts, nFeature_RNA becomes n_genes. applicable h5Seurat h5ad conversions. Default FALSE. ... Arguments passed methods","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"source character, invisibly returns dest; otherwise, returns H5File, filetype-specific subclass H5File (eg. h5Seurat), connection dest","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"anndata-h-ad-to-h-seurat","dir":"Reference","previous_headings":"","what":"AnnData/H5AD to h5Seurat","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"AnnData/H5AD h5Seurat conversion try automatically fill datasets based data presence. works following manner:","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"expression-data","dir":"Reference","previous_headings":"","what":"Expression data","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"expression matrices counts, data, scale.data  filled /X /raw/X following manner: counts filled /raw/X present;   otherwise, filled /X data filled /raw/X /raw/X   present /X dense; otherwise, filled /X scale.data filled /X dense;   otherwise, empty Feature names taken feature-level metadata","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"feature-level-metadata","dir":"Reference","previous_headings":"","what":"Feature-level metadata","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"Feature-level metadata added meta.features datasets assay. Feature names taken dataset specified “_index” attribute, “_index” dataset, “index” dataset, order. Metadata populated /raw/var present, otherwise /var; /raw/var /var present, meta.features populated /raw/var first, /var added . columns present /raw/var /var, values /var used instead. Note: possible /var fewer features /raw/var; case, features present /var overwritten, metadata features present /var remaining /raw/var empty","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"cell-level-metadata","dir":"Reference","previous_headings":"","what":"Cell-level metadata","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"Cell-level metadata added meta.data; row names metadata (determined value “_index” attribute, “_index” dataset, “index” dataset, order) added “cell.names” dataset instead. “__categories” dataset present, dataset within “__categories” stored factor group. Cell-level metadata added HDF5 group unless factors present srtdisk.dtype.dataframe_as_group FALSE","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"dimensional-reduction-information-","dir":"Reference","previous_headings":"","what":"Dimensional reduction information:","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"Cell embeddings taken /obsm; dimensional reductions  named based names obsm removing preceding  “X_”.example, dimensional reduction named “X_pca”  /obsm, resulting dimensional reduction information  named “pca”. key set one following: “PC_” “pca” present dimensional reduction   name (grepl(\"pca\", reduction.name, ignore.case = TRUE)) “tSNE_” “tsne” present dimensional   reduction name (grepl(\"tsne\", reduction.name, ignore.case = TRUE)) reduction.name_ reductions Remember preceding “X_” removed reduction  name converting key. Feature loadings taken  /varm placed associated dimensional reduction.  dimensional reduction determine loadings name /varm: “PCs” added dimensional reduction named   “pca” loadings /varm added dimensional   reduction named tolower(loading) (eg. loading named “ICA”   added dimensional reduction named “ica”) dimensional reduction found according rules ,  loading taken AnnData/H5AD file. Miscellaneous  information taken /uns/reduction reduction  name reduction /obsm without preceding  “X_”; dimensional reduction information present,  miscellaneous information taken AnnData/H5AD file.  Standard deviations taken dataset /uns/reduction/variance;  variances converted standard deviations added  stdev dataset dimensional reduction","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"nearest-neighbor-graph","dir":"Reference","previous_headings":"","what":"Nearest-neighbor graph","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"nearest neighbor graph present /uns/neighbors/distances,  added graph dataset h5Seurat file associated  assay; value present /uns/neighbors/params/method,  name graph assay_method, otherwise,  assay_anndata","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"layers","dir":"Reference","previous_headings":"","what":"Layers","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"TODO: add ","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"miscellaneous-information","dir":"Reference","previous_headings":"","what":"Miscellaneous information","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"groups datasets /uns copied misc  h5Seurat file except following: group dataset named dimensional reduction (eg.   /uns/pca) /uns/neighbors","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"h-seurat-to-anndata-h-ad","dir":"Reference","previous_headings":"","what":"h5Seurat to AnnData/H5AD","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"h5Seurat AnnData/H5AD conversion try automatically fill datasets based data presence. Data presense determined h5Seurat index (source$index()). works following manner:","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"assay-data","dir":"Reference","previous_headings":"","what":"Assay data","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"X filled scale.data scale.data   present; otherwise, filled data var filled meta.features   features present X; example, X filled   scale.data, var contain features   scaled raw.X filled data X filled   scale.data; otherwise, filled counts.   counts present, raw filled raw.var filled meta.features   features present raw.X; raw.X filled,   raw.var filled","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"cell-level-metadata-1","dir":"Reference","previous_headings":"","what":"Cell-level metadata","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"Cell-level metadata added obs","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"dimensional-reduction-information","dir":"Reference","previous_headings":"","what":"Dimensional reduction information","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"dimensional reductions associated assay marked  global transfered H5AD file.  every reduction reduc: cell embeddings placed obsm renamed   X_reduc feature loadings, present, placed varm renamed   either “PCs” reduc “pca” otherwise   reduc caps example, reduc “ica”, cell embeddings  “X_ica” obsm feature loaodings, present,  “ICA” varm","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"nearest-neighbor-graphs","dir":"Reference","previous_headings":"","what":"Nearest-neighbor graphs","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"nearest-neighbor graph associated assay,  added uns/neighbors/distances; one graph present,  last graph according index added.","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Convert.html","id":"layers-1","dir":"Reference","previous_headings":"","what":"Layers","title":"Convert an on-disk single-cell dataset to another format — Convert","text":"Data assays can added layers  shape X (number cells features). determine ,  shape alternate assays's scale.data data slots  determined. shape X, slot  (scale.data given priority data) added  layer named name assay (eg. “SCT”). addition,  features names added var assay_features  (eg. “SCT_features”).","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Dims.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the dimensions of an HDF5 dataset or sparse matrix — Dims","title":"Get the dimensions of an HDF5 dataset or sparse matrix — Dims","text":"Get dimensions HDF5 dataset sparse matrix","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Dims.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the dimensions of an HDF5 dataset or sparse matrix — Dims","text":"","code":"Dims(x)"},{"path":"https://mianaz.github.io/srtdisk/reference/Dims.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the dimensions of an HDF5 dataset or sparse matrix — Dims","text":"x HDF5 dataset sparse matrix","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Dims.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the dimensions of an HDF5 dataset or sparse matrix — Dims","text":"vector dimensions dataset sparse matrix. sparse matrices, dimensions found either “dims” “shape” attribute, returns c(NA_integer_, NA_integer_)","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/FileType.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine a filetype based on its extension — FileType","title":"Determine a filetype based on its extension — FileType","text":"Determine filetype based extension","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/FileType.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine a filetype based on its extension — FileType","text":"","code":"FileType(file)"},{"path":"https://mianaz.github.io/srtdisk/reference/FileType.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine a filetype based on its extension — FileType","text":"file Name file","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/FileType.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine a filetype based on its extension — FileType","text":"extension, lowercase","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/FileType.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine a filetype based on its extension — FileType","text":"","code":"# \\donttest{ srtdisk:::FileType('pbmc3k.h5Seurat') #> [1] \"h5seurat\" srtdisk:::FileType('h5ad') #> [1] \"h5ad\" # }"},{"path":"https://mianaz.github.io/srtdisk/reference/FixFeatures.html","id":null,"dir":"Reference","previous_headings":"","what":"Fix Feature Names — FixFeatures","title":"Fix Feature Names — FixFeatures","text":"Fix Feature Names","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/FixFeatures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fix Feature Names — FixFeatures","text":"","code":"FixFeatures(features)"},{"path":"https://mianaz.github.io/srtdisk/reference/FixFeatures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fix Feature Names — FixFeatures","text":"features vector feature names","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/FixFeatures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fix Feature Names — FixFeatures","text":"Fixed features","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GetClass.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a class string with package information — GetClass","title":"Get a class string with package information — GetClass","text":"S4 classes useful context defining package (benefits stricter typing). order ensure class information properly retained HDF5 files, S4 class names written “package:classname” certain exceptions (eg. S4 classes defined Seurat)","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GetClass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a class string with package information — GetClass","text":"","code":"GetClass(class, packages = \"Seurat\")"},{"path":"https://mianaz.github.io/srtdisk/reference/GetClass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a class string with package information — GetClass","text":"class Class name packages vector packages exclude resulting class information","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GetClass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a class string with package information — GetClass","text":"character vector class","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GetClass.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a class string with package information — GetClass","text":"","code":"# \\donttest{ srtdisk:::GetClass('Seurat') #> [1] \"SeuratObject:Seurat\" srtdisk:::GetClass('Matrix') #> [1] \"Matrix:Matrix\" # }"},{"path":"https://mianaz.github.io/srtdisk/reference/GetMargin.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine the margin to use for a dataset — GetMargin","title":"Determine the margin to use for a dataset — GetMargin","text":"Determine margin use dataset","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GetMargin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine the margin to use for a dataset — GetMargin","text":"","code":"GetMargin(dims, MARGIN = getOption(x = \"SeuratDisk.chunking.MARGIN\"))"},{"path":"https://mianaz.github.io/srtdisk/reference/GetMargin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine the margin to use for a dataset — GetMargin","text":"dims Dimensions dataset MARGIN Either integer value contained within 1:length(x = dims) one possible values SeuratDisk.chunking.MARGIN","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GetMargin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine the margin to use for a dataset — GetMargin","text":"integer value MARGIN","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/GetMargin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine the margin to use for a dataset — GetMargin","text":"","code":"# \\donttest{ srtdisk:::GetMargin(c(4, 10)) #> [1] 2 # }"},{"path":"https://mianaz.github.io/srtdisk/reference/GetObject.html","id":null,"dir":"Reference","previous_headings":"","what":"Figure out which objects to load from an h5Seurat file — GetObject","title":"Figure out which objects to load from an h5Seurat file — GetObject","text":"Figure objects load h5Seurat file","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GetObject.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Figure out which objects to load from an h5Seurat file — GetObject","text":"","code":"GetAssays(assays, index)  GetCommands(index, assays = NULL)  GetDimReducs(reductions, index, assays = NULL)  GetGraphs(graphs, index, assays = NULL)  GetImages(images, index, assays = NULL)  GetNeighbors(neighbors, index)"},{"path":"https://mianaz.github.io/srtdisk/reference/GetObject.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Figure out which objects to load from an h5Seurat file — GetObject","text":"assays One : character vector names assays character vector one counts, data,  scale.data describing slots assays load named list entry either name assay vector  describing slots (described ) take assay NULL assays index h5Seurat index (h5SI) object reductions One : character vector names reductions NULL reductions NA global reductions FALSE reductions Note: reductions associated assay loaded assays marked global loaded graphs One : character vector names graphs NULL graphs FALSE graphs Note: graphs associated assay loaded assays loaded images One : character vector names images NULL images NA global images FALSE images neighbors One : character vector names neighbors NULL neighbors FALSE neighbors","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GetObject.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Figure out which objects to load from an h5Seurat file — GetObject","text":"GetAssays: named list entry vector describing slots assay load names assays load GetCommands: vector command log names derived assay assay GetDimReducs: vector reduction names derived assay assays global dimensional reductions GetGraphs: vector graph names derived assay assays GetImages: vector image names GetNeighbors: vector neighbor names","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/GetParent.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the parent of an HDF5 dataset or group — GetParent","title":"Get the parent of an HDF5 dataset or group — GetParent","text":"Get parent HDF5 dataset group","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GetParent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the parent of an HDF5 dataset or group — GetParent","text":"","code":"GetParent(x)"},{"path":"https://mianaz.github.io/srtdisk/reference/GetParent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the parent of an HDF5 dataset or group — GetParent","text":"x HDF5 dataset group","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GetParent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the parent of an HDF5 dataset or group — GetParent","text":"H5File H5Group object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GuessDType.html","id":null,"dir":"Reference","previous_headings":"","what":"Guess an HDF5 Datatype — GuessDType","title":"Guess an HDF5 Datatype — GuessDType","text":"Wrapper around hdf5r::guess_dtype, allowing customization string types rather defaulting variable-length ASCII-encoded strings. Also encodes logicals H5T_INTEGER instead H5T_LOGICAL ensure cross-language compatibility (controlled via package options)","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GuessDType.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Guess an HDF5 Datatype — GuessDType","text":"","code":"GuessDType(x, stype = \"utf8\", ...)"},{"path":"https://mianaz.github.io/srtdisk/reference/GuessDType.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Guess an HDF5 Datatype — GuessDType","text":"x object guess HDF5 datatype dimension number elements stype Type string encoding use, choose : utf8 Variable-width, UTF-8 ascii7 Fixed-width (7 bits), ASCII ... Arguments passed hdf5r::guess_dtype ds_dim Can explicitly set dimension dataset object. scalar, one. Otherwise, can used multi-dimensional object can represented dimension dataset, inside H5T_ARRAY scalar datatype created x can represented scalar datatype? intended know vector/array represented H5T_ARRAY . string_len string R object, length corresponding HDF5 type set. positive integer, string length. Inf, variable length. set estimate, set length longest string x.","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/GuessDType.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Guess an HDF5 Datatype — GuessDType","text":"object class H5T","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/GuessDType.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Guess an HDF5 Datatype — GuessDType","text":"","code":"# \\donttest{ # Characters can either be variable-width UTF8-encoded or # fixed-width ASCII-encoded srtdisk:::GuessDType(x = 'hello') #> Class: H5T_STRING #> Datatype: H5T_STRING { #>       STRSIZE H5T_VARIABLE; #>       STRPAD H5T_STR_NULLTERM; #>       CSET H5T_CSET_UTF8; #>       CTYPE H5T_C_S1; #>    } srtdisk:::GuessDType(x = 'hello', stype = 'ascii7') #> Class: H5T_STRING #> Datatype: H5T_STRING { #>       STRSIZE 7; #>       STRPAD H5T_STR_NULLTERM; #>       CSET H5T_CSET_ASCII; #>       CTYPE H5T_C_S1; #>    }  # Data frames are a compound type; character columns follow the same rules # as character vectors df <- data.frame(x = c('g1', 'g2', 'g3'), y = 1, 2, 3, stringsAsFactors = FALSE) srtdisk:::GuessDType(x = df) #> Class: H5T_COMPOUND #> Datatype: H5T_COMPOUND { #>       H5T_STRING { #>          STRSIZE H5T_VARIABLE; #>          STRPAD H5T_STR_NULLTERM; #>          CSET H5T_CSET_UTF8; #>          CTYPE H5T_C_S1; #>       } \"x\" : 0; #>       H5T_IEEE_F64LE \"y\" : 8; #>       H5T_IEEE_F64LE \"X2\" : 16; #>       H5T_IEEE_F64LE \"X3\" : 24; #>    } srtdisk:::GuessDType(x = df, stype = 'ascii7') #> Class: H5T_COMPOUND #> Datatype: H5T_COMPOUND { #>       H5T_STRING { #>          STRSIZE 7; #>          STRPAD H5T_STR_NULLTERM; #>          CSET H5T_CSET_ASCII; #>          CTYPE H5T_C_S1; #>       } \"x\" : 0; #>       H5T_IEEE_F64LE \"y\" : 7; #>       H5T_IEEE_F64LE \"X2\" : 15; #>       H5T_IEEE_F64LE \"X3\" : 23; #>    }  # Logicals are turned into integers to ensure compatibility with Python # TRUE evaluates to 1, FALSE to 0, and NA to 2 srtdisk:::GuessDType(x = c(TRUE, FALSE, NA)) #> Class: H5T_INTEGER #> Datatype: H5T_STD_I32LE # }"},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"Convert AnnData/H5AD files h5Seurat files","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"","code":"H5ADToH5Seurat(source, dest, assay = \"RNA\", overwrite = FALSE, verbose = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"source Source dataset dest Name destination dataset assay Converting h5Seurat: name assay write ; converting h5Seurat: name store assay data overwrite Overwrite existing dest verbose Show progress updates","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"Returns handle dest h5Seurat object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"anndata-h-ad-to-h-seurat","dir":"Reference","previous_headings":"","what":"AnnData/H5AD to h5Seurat","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"AnnData/H5AD h5Seurat conversion try automatically fill datasets based data presence. works following manner:","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"expression-data","dir":"Reference","previous_headings":"","what":"Expression data","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"expression matrices counts, data, scale.data  filled /X /raw/X following manner: counts filled /raw/X present;   otherwise, filled /X data filled /raw/X /raw/X   present /X dense; otherwise, filled /X scale.data filled /X dense;   otherwise, empty Feature names taken feature-level metadata","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"feature-level-metadata","dir":"Reference","previous_headings":"","what":"Feature-level metadata","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"Feature-level metadata added meta.features datasets assay. Feature names taken dataset specified “_index” attribute, “_index” dataset, “index” dataset, order. Metadata populated /raw/var present, otherwise /var; /raw/var /var present, meta.features populated /raw/var first, /var added . columns present /raw/var /var, values /var used instead. Note: possible /var fewer features /raw/var; case, features present /var overwritten, metadata features present /var remaining /raw/var empty","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"cell-level-metadata","dir":"Reference","previous_headings":"","what":"Cell-level metadata","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"Cell-level metadata added meta.data; row names metadata (determined value “_index” attribute, “_index” dataset, “index” dataset, order) added “cell.names” dataset instead. “__categories” dataset present, dataset within “__categories” stored factor group. Cell-level metadata added HDF5 group unless factors present srtdisk.dtype.dataframe_as_group FALSE","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"dimensional-reduction-information-","dir":"Reference","previous_headings":"","what":"Dimensional reduction information:","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"Cell embeddings taken /obsm; dimensional reductions  named based names obsm removing preceding  “X_”.example, dimensional reduction named “X_pca”  /obsm, resulting dimensional reduction information  named “pca”. key set one following: “PC_” “pca” present dimensional reduction   name (grepl(\"pca\", reduction.name, ignore.case = TRUE)) “tSNE_” “tsne” present dimensional   reduction name (grepl(\"tsne\", reduction.name, ignore.case = TRUE)) reduction.name_ reductions Remember preceding “X_” removed reduction  name converting key. Feature loadings taken  /varm placed associated dimensional reduction.  dimensional reduction determine loadings name /varm: “PCs” added dimensional reduction named   “pca” loadings /varm added dimensional   reduction named tolower(loading) (eg. loading named “ICA”   added dimensional reduction named “ica”) dimensional reduction found according rules ,  loading taken AnnData/H5AD file. Miscellaneous  information taken /uns/reduction reduction  name reduction /obsm without preceding  “X_”; dimensional reduction information present,  miscellaneous information taken AnnData/H5AD file.  Standard deviations taken dataset /uns/reduction/variance;  variances converted standard deviations added  stdev dataset dimensional reduction","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"nearest-neighbor-graph","dir":"Reference","previous_headings":"","what":"Nearest-neighbor graph","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"nearest neighbor graph present /uns/neighbors/distances,  added graph dataset h5Seurat file associated  assay; value present /uns/neighbors/params/method,  name graph assay_method, otherwise,  assay_anndata","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"layers","dir":"Reference","previous_headings":"","what":"Layers","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"TODO: add ","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5ADToH5Seurat.html","id":"miscellaneous-information","dir":"Reference","previous_headings":"","what":"Miscellaneous information","title":"Convert AnnData/H5AD files to h5Seurat files — H5ADToH5Seurat","text":"groups datasets /uns copied misc  h5Seurat file except following: group dataset named dimensional reduction (eg.   /uns/pca) /uns/neighbors","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5Exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Check to see if a dataset, group, or attribute exists in an HDF5 file, group, or dataset — H5Exists","title":"Check to see if a dataset, group, or attribute exists in an HDF5 file, group, or dataset — H5Exists","text":"Check see dataset, group, attribute exists HDF5 file, group, dataset","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5Exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check to see if a dataset, group, or attribute exists in an HDF5 file, group, or dataset — H5Exists","text":"","code":"AttrExists(x, name)  Exists(x, name)"},{"path":"https://mianaz.github.io/srtdisk/reference/H5Exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check to see if a dataset, group, or attribute exists in an HDF5 file, group, or dataset — H5Exists","text":"x HDF5 file group; AttrExists, may also dataset name Name dataset, group, attribute test ","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5Exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check to see if a dataset, group, or attribute exists in an HDF5 file, group, or dataset — H5Exists","text":"TRUE name exists x, otherwise FALSE","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5Path.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an HDF5 object path — H5Path","title":"Create an HDF5 object path — H5Path","text":"Create HDF5 object path","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5Path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an HDF5 object path — H5Path","text":"","code":"H5Path(..., collapse = NULL)"},{"path":"https://mianaz.github.io/srtdisk/reference/H5Path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an HDF5 object path — H5Path","text":"... one R objects, converted character vectors. collapse optional character string separate results.      NA_character_.","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5Path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an HDF5 object path — H5Path","text":"character vector path ready accessing data HDF5 file group","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5SeuratToH5AD.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","title":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","text":"Convert h5Seurat files H5AD files","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5SeuratToH5AD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","text":"","code":"H5SeuratToH5AD(   source,   dest,   assay = DefaultAssay(object = source),   overwrite = FALSE,   verbose = TRUE,   standardize = FALSE )"},{"path":"https://mianaz.github.io/srtdisk/reference/H5SeuratToH5AD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","text":"source Source dataset dest Name destination dataset assay Converting h5Seurat: name assay write ; converting h5Seurat: name store assay data overwrite Overwrite existing dest verbose Show progress updates standardize Logical; TRUE, convert Seurat-style metadata column names scanpy/AnnData conventions. example, nCount_RNA becomes n_counts, nFeature_RNA becomes n_genes. Default FALSE.","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5SeuratToH5AD.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","text":"Returns handle dest H5File object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5SeuratToH5AD.html","id":"h-seurat-to-anndata-h-ad","dir":"Reference","previous_headings":"","what":"h5Seurat to AnnData/H5AD","title":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","text":"h5Seurat AnnData/H5AD conversion try automatically fill datasets based data presence. Data presense determined h5Seurat index (source$index()). works following manner:","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5SeuratToH5AD.html","id":"assay-data","dir":"Reference","previous_headings":"","what":"Assay data","title":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","text":"X filled scale.data scale.data   present; otherwise, filled data var filled meta.features   features present X; example, X filled   scale.data, var contain features   scaled raw.X filled data X filled   scale.data; otherwise, filled counts.   counts present, raw filled raw.var filled meta.features   features present raw.X; raw.X filled,   raw.var filled","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5SeuratToH5AD.html","id":"cell-level-metadata","dir":"Reference","previous_headings":"","what":"Cell-level metadata","title":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","text":"Cell-level metadata added obs","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5SeuratToH5AD.html","id":"dimensional-reduction-information","dir":"Reference","previous_headings":"","what":"Dimensional reduction information","title":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","text":"dimensional reductions associated assay marked  global transfered H5AD file.  every reduction reduc: cell embeddings placed obsm renamed   X_reduc feature loadings, present, placed varm renamed   either “PCs” reduc “pca” otherwise   reduc caps example, reduc “ica”, cell embeddings  “X_ica” obsm feature loaodings, present,  “ICA” varm","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5SeuratToH5AD.html","id":"nearest-neighbor-graphs","dir":"Reference","previous_headings":"","what":"Nearest-neighbor graphs","title":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","text":"nearest-neighbor graph associated assay,  added uns/neighbors/distances; one graph present,  last graph according index added.","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/H5SeuratToH5AD.html","id":"layers","dir":"Reference","previous_headings":"","what":"Layers","title":"Convert h5Seurat files to H5AD files — H5SeuratToH5AD","text":"Data assays can added layers  shape X (number cells features). determine ,  shape alternate assays's scale.data data slots  determined. shape X, slot  (scale.data given priority data) added  layer named name assay (eg. “SCT”). addition,  features names added var assay_features  (eg. “SCT_features”).","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ImageWrite.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a SpatialImage object to an HDF5 dataset — ImageWrite","title":"Write a SpatialImage object to an HDF5 dataset — ImageWrite","text":"Write SpatialImage object HDF5 dataset","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ImageWrite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a SpatialImage object to an HDF5 dataset — ImageWrite","text":"","code":"ImageWrite(x, name, hgroup, verbose = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/ImageWrite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a SpatialImage object to an HDF5 dataset — ImageWrite","text":"x object name Name save data hgroup HDF5 file group (H5File H5Group objects hdf5r) verbose Show progress updates","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ImageWrite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a SpatialImage object to an HDF5 dataset — ImageWrite","text":"Invisibly returns NULL","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/IsDType.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the datatype of an HDF5 dataset — IsDType","title":"Check the datatype of an HDF5 dataset — IsDType","text":"Effectively, implementation HDF5 datasets; useful ensure HDF5 validity specific file structures","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/IsDType.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the datatype of an HDF5 dataset — IsDType","text":"","code":"IsDType(x, dtype)"},{"path":"https://mianaz.github.io/srtdisk/reference/IsDType.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the datatype of an HDF5 dataset — IsDType","text":"x HDF5 dataset (object type H5D) dtype character vector HDF5 datatype names, must present h5types","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/IsDType.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check the datatype of an HDF5 dataset — IsDType","text":"logical","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/IsMatrixEmpty.html","id":null,"dir":"Reference","previous_headings":"","what":"Check to see if a matrix is empty — IsMatrixEmpty","title":"Check to see if a matrix is empty — IsMatrixEmpty","text":"Determine matrix empty . matrix considered empty satisfies one following conditions: dimensions matrix 0--0 ((dim(x) == 0)) dimensions matrix 1--1 ((dim(x) == 1))  sole vlaue NA two situations correspond matrices generated either new('matrix') matrix()","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/IsMatrixEmpty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check to see if a matrix is empty — IsMatrixEmpty","text":"","code":"IsMatrixEmpty(x)"},{"path":"https://mianaz.github.io/srtdisk/reference/IsMatrixEmpty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check to see if a matrix is empty — IsMatrixEmpty","text":"x matrix","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/IsMatrixEmpty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check to see if a matrix is empty — IsMatrixEmpty","text":"TRUE matrix empty otherwise FALSE","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/IsMatrixEmpty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check to see if a matrix is empty — IsMatrixEmpty","text":"","code":"# \\donttest{ srtdisk:::IsMatrixEmpty(new('matrix')) #> [1] TRUE srtdisk:::IsMatrixEmpty(matrix()) #> [1] TRUE srtdisk:::IsMatrixEmpty(matrix(1:9, nrow = 3)) #> [1] FALSE # }"},{"path":"https://mianaz.github.io/srtdisk/reference/IsSCDisk.html","id":null,"dir":"Reference","previous_headings":"","what":"Does an R6 class inherit from scdisk — IsSCDisk","title":"Does an R6 class inherit from scdisk — IsSCDisk","text":"R6 class inherit scdisk","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/IsSCDisk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Does an R6 class inherit from scdisk — IsSCDisk","text":"","code":"IsSCDisk(r6class)"},{"path":"https://mianaz.github.io/srtdisk/reference/IsSCDisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Does an R6 class inherit from scdisk — IsSCDisk","text":"r6class R6 class generator character name R6 class generator","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/IsSCDisk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Does an R6 class inherit from scdisk — IsSCDisk","text":"r6class inherits scdisk, returns TRUE; otherwise, returns FALSE","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/IsSCDisk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Does an R6 class inherit from scdisk — IsSCDisk","text":"","code":"# \\donttest{ srtdisk:::IsSCDisk(\"H5File\") #> [1] FALSE srtdisk:::IsSCDisk(\"scdisk\") #> [1] TRUE srtdisk:::IsSCDisk(\"h5Seurat\") #> [1] TRUE # }"},{"path":"https://mianaz.github.io/srtdisk/reference/LoadH5Seurat.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a saved Seurat object from an h5Seurat file — LoadH5Seurat","title":"Load a saved Seurat object from an h5Seurat file — LoadH5Seurat","text":"Load saved Seurat object h5Seurat file","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoadH5Seurat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a saved Seurat object from an h5Seurat file — LoadH5Seurat","text":"","code":"LoadH5Seurat(file, ...)  # S3 method for class 'character' LoadH5Seurat(   file,   assays = NULL,   reductions = NULL,   graphs = NULL,   neighbors = NULL,   images = NULL,   meta.data = TRUE,   commands = TRUE,   misc = is.null(x = assays),   tools = is.null(x = assays),   verbose = TRUE,   ... )  # S3 method for class 'H5File' LoadH5Seurat(   file,   assays = NULL,   reductions = NULL,   graphs = NULL,   neighbors = NULL,   images = NULL,   meta.data = TRUE,   commands = TRUE,   misc = is.null(x = assays),   tools = is.null(x = assays),   verbose = TRUE,   ... )  # S3 method for class 'h5Seurat' LoadH5Seurat(   file,   assays = NULL,   reductions = NULL,   graphs = NULL,   neighbors = NULL,   images = NULL,   meta.data = TRUE,   commands = TRUE,   misc = is.null(x = assays),   tools = is.null(x = assays),   verbose = TRUE,   ... )  # S3 method for class 'h5Seurat' as.Seurat(   x,   assays = NULL,   reductions = NULL,   graphs = NULL,   neighbors = NULL,   images = NULL,   meta.data = TRUE,   commands = TRUE,   misc = TRUE,   tools = TRUE,   verbose = TRUE,   ... )"},{"path":"https://mianaz.github.io/srtdisk/reference/LoadH5Seurat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a saved Seurat object from an h5Seurat file — LoadH5Seurat","text":"file, x Name h5Seurat connected h5Seurat file load ... Arguments passed methods assays One : character vector names assays character vector one counts, data,  scale.data describing slots assays load named list entry either name assay vector  describing slots (described ) take assay NULL assays reductions One : character vector names reductions NULL reductions NA global reductions FALSE reductions Note: reductions associated assay loaded assays marked global loaded graphs One : character vector names graphs NULL graphs FALSE graphs Note: graphs associated assay loaded assays loaded neighbors One : character vector names neighbors NULL neighbors FALSE neighbors images One : character vector names images NULL images NA global images FALSE images meta.data Load object metadata commands Load command information Note: commands associated assay loaded assays loaded misc Load miscellaneous data tools Load tool-specific information verbose Show progress updates","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoadH5Seurat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a saved Seurat object from an h5Seurat file — LoadH5Seurat","text":"Seurat object data requested","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoadLoom.html","id":null,"dir":"Reference","previous_headings":"","what":"Loom-file Loading — LoadLoom","title":"Loom-file Loading — LoadLoom","text":"Load data loom file Seurat object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoadLoom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loom-file Loading — LoadLoom","text":"","code":"LoadLoom(   file,   assay = NULL,   cells = \"CellID\",   features = \"Gene\",   normalized = NULL,   scaled = NULL,   filter = c(\"cells\", \"features\", \"all\", \"none\"),   verbose = TRUE,   ... )  # S3 method for class 'character' LoadLoom(file, ...)  # S3 method for class 'H5File' LoadLoom(file, ...)  # S3 method for class 'loom' LoadLoom(file, ...)  # S3 method for class 'loom' as.Seurat(   x,   assay = NULL,   cells = \"CellID\",   features = \"Gene\",   normalized = NULL,   scaled = NULL,   filter = c(\"cells\", \"features\", \"all\", \"none\"),   verbose = TRUE,   ... )"},{"path":"https://mianaz.github.io/srtdisk/reference/LoadLoom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loom-file Loading — LoadLoom","text":"file, x Name loom file loom object load data assay Name assay store expression data ; NULL, search HDF5 attribute named SEURAT_ASSAY attribute dataset named /attrs/SEURAT_ASSAY assay name. found, defaults “RNA” cells Name dataset /col_attrs cell names features Name dataset /row_attrs feature names normalized Name matrix /layers store normalized data ; pass “/matrix” store /matrix normalized data instead raw counts scaled Name dataset /layers store scaled data filter Keep selected cells /features specified /col_attrs/Valid /row_attrs/Valid, respectively verbose Show progress updates ... Arguments passed methods","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoadLoom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loom-file Loading — LoadLoom","text":"Seurat object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoadLoom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loom-file Loading — LoadLoom","text":"LoadLoom try automatically fill slots Seurat object based data presence absence given loom file. method varies loom specification version. version-specific details, see sections ","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoadLoom.html","id":"loom-loading","dir":"Reference","previous_headings":"","what":"Loom 0.1 Loading","title":"Loom-file Loading — LoadLoom","text":"Loading data loom files less version 3.0.0 currently supported","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoadLoom.html","id":"loom-loading-1","dir":"Reference","previous_headings":"","what":"Loom 3.0.0 Loading","title":"Loom-file Loading — LoadLoom","text":"blah","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/LoomLoading.html","id":null,"dir":"Reference","previous_headings":"","what":"Loom-file Loading — LoomLoading","title":"Loom-file Loading — LoomLoading","text":"Version-specific loom-file loading functions","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoomLoading.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loom-file Loading — LoomLoading","text":"","code":"LoadLoom0.1(   file,   assay = NULL,   cells = \"col_atts/CellID\",   features = \"row_attrs/Gene\",   normalized = NULL,   scaled = NULL,   filter = c(\"cells\", \"features\", \"all\", \"none\"),   verbose = TRUE )  LoadLoom3.0(   file,   assay = NULL,   cells = \"col_attrs/CellID\",   features = \"row_attrs/Gene\",   normalized = NULL,   scaled = NULL,   filter = c(\"cells\", \"features\", \"all\", \"none\"),   verbose = TRUE )"},{"path":"https://mianaz.github.io/srtdisk/reference/LoomLoading.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loom-file Loading — LoomLoading","text":"assay Name assay store expression data ; NULL, search HDF5 attribute named SEURAT_ASSAY attribute dataset named /attrs/SEURAT_ASSAY assay name. found, defaults “RNA” cells Name dataset /col_attrs cell names features Name dataset /row_attrs feature names normalized Name matrix /layers store normalized data ; pass “/matrix” store /matrix normalized data instead raw counts scaled Name dataset /layers store scaled data filter Keep selected cells /features specified /col_attrs/Valid /row_attrs/Valid, respectively verbose Show progress updates","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoomLoading.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loom-file Loading — LoomLoading","text":"Seurat object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoomLoading.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loom-file Loading — LoomLoading","text":"LoadLoom try automatically fill slots Seurat object based data presence absence given loom file. method varies loom specification version. version-specific details, see sections ","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoomLoading.html","id":"loom-loading","dir":"Reference","previous_headings":"","what":"Loom 0.1 Loading","title":"Loom-file Loading — LoomLoading","text":"Loading data loom files less version 3.0.0 currently supported","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/LoomLoading.html","id":"loom-loading-1","dir":"Reference","previous_headings":"","what":"Loom 3.0.0 Loading","title":"Loom-file Loading — LoomLoading","text":"blah","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/MakeSpace.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a space — MakeSpace","title":"Make a space — MakeSpace","text":"Generate blank space n characters long; useful aligning text printed console","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/MakeSpace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a space — MakeSpace","text":"","code":"MakeSpace(n)"},{"path":"https://mianaz.github.io/srtdisk/reference/MakeSpace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a space — MakeSpace","text":"n Length space ","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/MakeSpace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a space — MakeSpace","text":"space (' ') length n","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/MakeSpace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a space — MakeSpace","text":"","code":"# \\donttest{ srtdisk:::MakeSpace(n = 10) #> [1] \"          \" cat('hello', srtdisk:::MakeSpace(n = 10), 'world\\n', sep = '') #> hello          world # }"},{"path":"https://mianaz.github.io/srtdisk/reference/PB.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a progress bar — PB","title":"Create a progress bar — PB","text":"Progress bars useful ways getting updates close task completion. However, can get way RMarkdown documents lots unnecesssary printing. PB convenience function creates progress bars following defaults char = '=' style = 3 file = stderr()","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/PB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a progress bar — PB","text":"","code":"PB()"},{"path":"https://mianaz.github.io/srtdisk/reference/PB.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a progress bar — PB","text":"object class txtProgressBar","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/PB.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a progress bar — PB","text":"","code":"# \\donttest{ pb <- srtdisk:::PB() for (i in 1:10) {   utils::setTxtProgressBar(pb, i / 10) } close(pb) # }"},{"path":"https://mianaz.github.io/srtdisk/reference/PadMatrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Pad a matrix — PadMatrix","title":"Pad a matrix — PadMatrix","text":"Pad matrix","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/PadMatrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pad a matrix — PadMatrix","text":"","code":"PadMatrix(src, dest, dname, dims, index)  # S4 method for class 'H5D' PadMatrix(src, dest, dname, dims, index)  # S4 method for class 'H5Group' PadMatrix(src, dest, dname, dims, index)"},{"path":"https://mianaz.github.io/srtdisk/reference/PadMatrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pad a matrix — PadMatrix","text":"src source matrix dest Destination HDF5 file group padded matrix dname Destination name padded matrix dims two-length integer vector number rows number columns padded matrix index two-length list integer vectors describing rows columns src exists ","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/PadMatrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pad a matrix — PadMatrix","text":"...","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/PadNames.html","id":null,"dir":"Reference","previous_headings":"","what":"Add names for unnamed or partially named objects — PadNames","title":"Add names for unnamed or partially named objects — PadNames","text":"Add names unnamed partially named objects","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/PadNames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add names for unnamed or partially named objects — PadNames","text":"","code":"PadNames(x, prefix = \"index\")"},{"path":"https://mianaz.github.io/srtdisk/reference/PadNames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add names for unnamed or partially named objects — PadNames","text":"x object can named prefix prefix added name","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/PadNames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add names for unnamed or partially named objects — PadNames","text":"x unnamed values named","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/PadNames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add names for unnamed or partially named objects — PadNames","text":"","code":"# \\donttest{ a <- list(1, b = 2, 3) srtdisk:::PadNames(a) #> $index1 #> [1] 1 #>  #> $b #> [1] 2 #>  #> $index3 #> [1] 3 #>  # }"},{"path":"https://mianaz.github.io/srtdisk/reference/RandomName.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a random string of characters — RandomName","title":"Generate a random string of characters — RandomName","text":"Generate random string characters","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/RandomName.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a random string of characters — RandomName","text":"","code":"RandomName(length = 5L, ...)"},{"path":"https://mianaz.github.io/srtdisk/reference/RandomName.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a random string of characters — RandomName","text":"length Length (nchar) string generate ... Extra parameters passed sample","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/RandomName.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a random string of characters — RandomName","text":"random string characters length (nchar) length","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/RandomName.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a random string of characters — RandomName","text":"","code":"# \\donttest{ srtdisk:::RandomName() #> [1] \"lbfdp\" # }"},{"path":"https://mianaz.github.io/srtdisk/reference/ReadH5.html","id":null,"dir":"Reference","previous_headings":"","what":"Load data from an HDF5 File — ReadH5","title":"Load data from an HDF5 File — ReadH5","text":"HDF5 allows storing data arbitrary fashion, makes reading data memory hassle. methods serve convenience functions reading data stored certain format back certain R object. details regarding data stored disk, please see h5Seurat file specification.","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ReadH5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load data from an HDF5 File — ReadH5","text":"","code":"# S3 method for class 'H5D' as.array(x, ...)  # S3 method for class 'H5D' as.data.frame(x, row.names = NULL, optional = FALSE, ...)  # S3 method for class 'H5Group' as.data.frame(x, row.names = NULL, optional = FALSE, ...)  # S4 method for class 'H5Group' as.factor(x)  # S4 method for class 'H5Group' as.list(x, which = NULL, ...)  # S3 method for class 'H5D' as.matrix(x, transpose = FALSE, ...)  # S3 method for class 'H5Group' as.matrix(x, ...)  # S3 method for class 'H5D' as.sparse(x, ...)  # S3 method for class 'H5Group' as.sparse(x, ...)"},{"path":"https://mianaz.github.io/srtdisk/reference/ReadH5.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load data from an HDF5 File — ReadH5","text":"x HDF5 dataset group ... Arguments passed methods Optional character vector specifying elements read H5Group row.names NULL character vector giving row     names data frame.  Missing values allowed. optional logical. TRUE, setting row names     converting column names (syntactic names: see     make.names) optional.  Note R's     base package .data.frame() methods use     optional column names treatment, basically     meaning data.frame(*, check.names = !optional).     See also make.names argument matrix method. transpose Transpose data upon reading , used writing data row-major order (eg. C Python)","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ReadH5.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load data from an HDF5 File — ReadH5","text":".array: returns array data HDF5 dataset .data.frame: returns data.frame data HDF5 dataset group .factor: returns factor data HDF5 group .list: returns list data HDF5 group .logical: returns logical data HDF5 dataset .matrix, H5D method: returns matrix data HDF5 dataset .sparse, H5D method: returns sparse matrix data HDF5 dataset .sparse, .matrix, H5Group method: returns sparseMatrix data HDF5 group dimnames: returns two-length list character vectors row column names. Row names column named index","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/RegisterSCDisk.html","id":null,"dir":"Reference","previous_headings":"","what":"Get and Register scdisk Subclasses — RegisterSCDisk","title":"Get and Register scdisk Subclasses — RegisterSCDisk","text":"Mechanisms registration scdisk subclass generators use functions rely class definition instead object.","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/RegisterSCDisk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get and Register scdisk Subclasses — RegisterSCDisk","text":"","code":"GetSCDisk(r6class = NULL)  RegisterSCDisk(r6class)"},{"path":"https://mianaz.github.io/srtdisk/reference/RegisterSCDisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get and Register scdisk Subclasses — RegisterSCDisk","text":"r6class R6 class generator character name R6 class generator","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/RegisterSCDisk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get and Register scdisk Subclasses — RegisterSCDisk","text":"GetSCDisk: r6class NULL, vector registered scdisk subclasses; otherwise, generator requested scdisk subclass RegisterSCDisk: adds r6class internal subclass registry invisibly returns NULL","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/RegisterSCDisk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get and Register scdisk Subclasses — RegisterSCDisk","text":"scdisk-subclassed objects (eg. h5Seurat objects) follow traditional inheritance patterns (can determined inherits), class definitions object generators . functions provide simple mechanism adding getting defintions scdisk subclasses functions utilize object generators aspects class definition (Convert) register subclass scdisk, simply add call RegisterSCDisk load hook","code":".onLoad <- function(libname, pkgname) {   RegisterSCDisk(classgen)   # Other code to be run on load }"},{"path":"https://mianaz.github.io/srtdisk/reference/RegisterSCDisk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get and Register scdisk Subclasses — RegisterSCDisk","text":"","code":"GetSCDisk() #> [1] \"h5Seurat\" \"loom\"     GetSCDisk(\"h5Seurat\") #> <h5Seurat> object generator #>   Inherits from: <scdisk> #>   Public: #>     index: function ()  #>     set.version: function (version)  #>     version: function ()  #>     detect.version: function ()  #>     is.v5: function ()  #>   Private: #>     index.internal: list #>     versions: 3.1.2 3.1.5.9900 5.0.0 5.2.1 #>     build.index: function (version)  #>     create: function (version, verbose = TRUE)  #>     validate: function (verbose = TRUE, ...)  #>     v3.1.2: function ()  #>     v3.2.0: function ()  #>     v5.0.0: function ()  #>   Parent env: <environment: namespace:srtdisk> #>   Locked objects: TRUE #>   Locked class: TRUE #>   Portable: TRUE  if (FALSE) { # \\dontrun{ RegisterSCDisk(h5Seurat) } # }"},{"path":"https://mianaz.github.io/srtdisk/reference/SaveH5Seurat.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a Seurat object to an h5Seurat file — SaveH5Seurat","title":"Save a Seurat object to an h5Seurat file — SaveH5Seurat","text":"Save Seurat object h5Seurat file","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SaveH5Seurat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a Seurat object to an h5Seurat file — SaveH5Seurat","text":"","code":"SaveH5Seurat(object, filename, overwrite = FALSE, verbose = TRUE, ...)  as.h5Seurat(x, ...)  # Default S3 method SaveH5Seurat(object, filename, overwrite = FALSE, verbose = TRUE, ...)  # S3 method for class 'Seurat' SaveH5Seurat(   object,   filename = paste0(Project(object = object), \".h5Seurat\"),   overwrite = FALSE,   verbose = TRUE,   ... )  # Default S3 method as.h5Seurat(x, filename, overwrite = FALSE, verbose = TRUE, ...)  # S3 method for class 'H5File' as.h5Seurat(x, ...)  # S3 method for class 'Seurat' as.h5Seurat(   x,   filename = paste0(Project(object = x), \".h5seurat\"),   overwrite = FALSE,   verbose = TRUE,   ... )"},{"path":"https://mianaz.github.io/srtdisk/reference/SaveH5Seurat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a Seurat object to an h5Seurat file — SaveH5Seurat","text":"object, x object filename Name file save object overwrite Overwrite filename present verbose Show progress updates ... Arguments passed methods","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SaveH5Seurat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a Seurat object to an h5Seurat file — SaveH5Seurat","text":"SaveH5Seurat: Invisbly returns filename .h5Seurat: h5Seurat object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SaveLoom.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a Seurat object to a loom file — SaveLoom","title":"Save a Seurat object to a loom file — SaveLoom","text":"Save Seurat object loom file","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SaveLoom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a Seurat object to a loom file — SaveLoom","text":"","code":"SaveLoom(object, filename, overwrite = FALSE, verbose = TRUE, ...)  as.loom(x, ...)  # Default S3 method SaveLoom(object, filename, overwrite = FALSE, verbose = TRUE, ...)  # S3 method for class 'Seurat' SaveLoom(   object,   filename = paste0(Project(object = object), \".loom\"),   overwrite = FALSE,   verbose = TRUE,   ... )  # Default S3 method as.loom(x, filename, overwrite = FALSE, verbose = TRUE, ...)  # S3 method for class 'H5File' as.loom(x, ...)  # S3 method for class 'Seurat' as.loom(   x,   filename = paste0(Project(object = x), \".loom\"),   overwrite = FALSE,   verbose = TRUE,   ... )"},{"path":"https://mianaz.github.io/srtdisk/reference/SaveLoom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a Seurat object to a loom file — SaveLoom","text":"object, x object filename Name file save object overwrite Overwrite filename present verbose Show progress updates ... Arguments passed methods","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SaveLoom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a Seurat object to a loom file — SaveLoom","text":"SaveLoom: Invisibly returns filename .loom: loom object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Scalar.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a scalar space — Scalar","title":"Create a scalar space — Scalar","text":"Create scalar space","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Scalar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a scalar space — Scalar","text":"","code":"Scalar()"},{"path":"https://mianaz.github.io/srtdisk/reference/Scalar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a scalar space — Scalar","text":"object type H5S denoting scalar HDF5 space","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SeuratDisk-package.html","id":null,"dir":"Reference","previous_headings":"","what":"srtdisk: Interfaces for HDF5-Based Single Cell File Formats — srtdisk-package","title":"srtdisk: Interfaces for HDF5-Based Single Cell File Formats — srtdisk-package","text":"h5Seurat file format specifically designed storage analysis multi-modal single-cell spatially-resolved expression experiments, example, CITE-seq 10X Visium technologies. holds molecular information associated metadata, including (example) nearest-neighbor graphs, dimensional reduction information, spatial coordinates image data, cluster labels. also support rapid -disk conversion h5Seurat AnnData objects, goal enhancing interoperability Seurat Scanpy.","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SeuratDisk-package.html","id":"package-options","dir":"Reference","previous_headings":"","what":"Package options","title":"srtdisk: Interfaces for HDF5-Based Single Cell File Formats — srtdisk-package","text":"srtdisk uses following options control behavior, users can configure options: srtdisk.dtypes.logical_to_int writing logical vectors, coerce integer types   ensure compatibility across languages (see BoolToInt   details) srtdisk.dtypes.dataframe_as_group writing data.frames, always write group   regardless factor presence srtdisk.chunking.MARGIN Default direction chunking datasets; choose : largest Chunk along largest dimension dataset smallest Chunk along smallest dimension first Chunk along first dimension last Chunk along last dimension  srtdisk.dimreducs.allglobal Treat DimReducs global, regardless actual global status","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/SeuratDisk-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"srtdisk: Interfaces for HDF5-Based Single Cell File Formats — srtdisk-package","text":"Maintainer: Paul Hoffman phoffman@nygenome.org (ORCID) contributors: Rahul Satija rsatija@nygenome.org (ORCID) [contributor]","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SparsePointers.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert sparse matrix pointers to indices and vice versa — SparsePointers","title":"Convert sparse matrix pointers to indices and vice versa — SparsePointers","text":"Convert sparse matrix pointers indices vice versa","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SparsePointers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert sparse matrix pointers to indices and vice versa — SparsePointers","text":"","code":"IndexToPointer(j)  PointerToIndex(p)"},{"path":"https://mianaz.github.io/srtdisk/reference/SparsePointers.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Convert sparse matrix pointers to indices and vice versa — SparsePointers","text":"PointerToIndex came StackOverflow","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SparsePointers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert sparse matrix pointers to indices and vice versa — SparsePointers","text":"j vector sparse matrix colum indices p vector sparse matrix pointers","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SparsePointers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert sparse matrix pointers to indices and vice versa — SparsePointers","text":"IndexToPointer: vector index pointers (p) PointerToIndex: vector column (j) indices","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SparsePointers.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert sparse matrix pointers to indices and vice versa — SparsePointers","text":"PointerToIndex written Josh O'Brien StackOverflow","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SparsePointers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert sparse matrix pointers to indices and vice versa — SparsePointers","text":"","code":"# \\donttest{ dat <- dat <- c(0, 0, 1, 4, 0, 2, 0, 9, 0) smat <- Matrix::Matrix(data = dat, nrow = 3, sparse = TRUE) j <- srtdisk:::PointerToIndex(p = smat@p) Matrix::sparseMatrix(i = smat@i + 1, j = j, x = smat@x) #> 3 x 3 sparse Matrix of class \"dgCMatrix\" #>            #> [1,] . 4 . #> [2,] . . 9 #> [3,] 1 2 . p <- srtdisk:::IndexToPointer(j = j) Matrix::sparseMatrix(i = smat@i + 1, p = p, x= smat@x) #> 3 x 3 sparse Matrix of class \"dgCMatrix\" #>            #> [1,] . 4 . #> [2,] . . 9 #> [3,] 1 2 . # }"},{"path":"https://mianaz.github.io/srtdisk/reference/SparseWrite.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a sparse matrix to an HDF5 dataset — SparseWrite","title":"Write a sparse matrix to an HDF5 dataset — SparseWrite","text":"Write sparse matrix HDF5 dataset","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SparseWrite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a sparse matrix to an HDF5 dataset — SparseWrite","text":"","code":"SparseWrite(x, name, hgroup, verbose = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/SparseWrite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a sparse matrix to an HDF5 dataset — SparseWrite","text":"x object name Name save data hgroup HDF5 file group (H5File H5Group objects hdf5r) verbose Show progress updates","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/SparseWrite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a sparse matrix to an HDF5 dataset — SparseWrite","text":"Invisibly returns NULL","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/StringType.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate an HDF5 string dtype — StringType","title":"Generate an HDF5 string dtype — StringType","text":"Presets encoding variations H5T_STRING; used generate HDF5 datatype specifications specific string encodings","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/StringType.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate an HDF5 string dtype — StringType","text":"","code":"StringType(stype = c(\"utf8\", \"ascii7\"))"},{"path":"https://mianaz.github.io/srtdisk/reference/StringType.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate an HDF5 string dtype — StringType","text":"stype Type string encoding use, choose : utf8 Variable-width, UTF-8 ascii7 Fixed-width (7 bits), ASCII","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/StringType.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate an HDF5 string dtype — StringType","text":"H5T_STRING object","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/StringType.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate an HDF5 string dtype — StringType","text":"","code":"# \\donttest{ srtdisk:::StringType() srtdisk:::StringType('ascii7') #> Class: H5T_STRING #> Datatype: H5T_STRING { #>       STRSIZE 7; #>       STRPAD H5T_STR_NULLTERM; #>       CSET H5T_CSET_ASCII; #>       CTYPE H5T_C_S1; #>    } # }"},{"path":"https://mianaz.github.io/srtdisk/reference/TestH5.html","id":null,"dir":"Reference","previous_headings":"","what":"Test HDF5 datasets and groups to see what kind of data they are — TestH5","title":"Test HDF5 datasets and groups to see what kind of data they are — TestH5","text":"Test HDF5 datasets groups see kind data ","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/TestH5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test HDF5 datasets and groups to see what kind of data they are — TestH5","text":"","code":"# S4 method for class 'H5D' IsDataFrame(x)  # S4 method for class 'H5Group' IsDataFrame(x)  # S4 method for class 'H5D' IsFactor(x)  # S4 method for class 'H5Group' IsFactor(x)  # S4 method for class 'H5Group' IsList(x)  # S4 method for class 'H5D' IsLogical(x)  # S4 method for class 'H5D' IsMatrix(x)  # S4 method for class 'H5Group' IsMatrix(x)"},{"path":"https://mianaz.github.io/srtdisk/reference/TestH5.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test HDF5 datasets and groups to see what kind of data they are — TestH5","text":"x HDF5 dataset group","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/TestObject.html","id":null,"dir":"Reference","previous_headings":"","what":"Test an object's class — TestObject","title":"Test an object's class — TestObject","text":"Generic functions testing object satisfies class membership","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/TestObject.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test an object's class — TestObject","text":"","code":"IsDataFrame(x)  IsFactor(x)  IsList(x)  IsLogical(x)  IsMatrix(x)"},{"path":"https://mianaz.github.io/srtdisk/reference/Timestamp.html","id":null,"dir":"Reference","previous_headings":"","what":"Create and work with timestamps — Timestamp","title":"Create and work with timestamps — Timestamp","text":"Create work timestamps","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Timestamp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create and work with timestamps — Timestamp","text":"","code":"FormatTime(time, locale = TRUE, tz = \"UTC\", format = TSFormats(type = \"R\"))  Timestamp(tz = \"UTC\", format = TSFormats(type = \"R\"))  TSFormats(type = c(\"R\", \"loom\"))"},{"path":"https://mianaz.github.io/srtdisk/reference/Timestamp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create and work with timestamps — Timestamp","text":"time character timestamp locale Change timestamp timezone locale determined Sys.timezone tz character string specifying time zone used     conversion.  System-specific (see .POSIXlt),     \"\" current time zone, \"GMT\" UTC.     Invalid values commonly treated UTC, platforms     warning. format character string.  default format     methods     \"%Y-%m-%d %H:%M:%S\" element time     component midnight, \"%Y-%m-%d\"     otherwise.  options(\"digits.secs\") set,     specified number digits printed seconds. type Type format get, currently supports following formats: “R” “loom” See Timestamp formats details","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Timestamp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create and work with timestamps — Timestamp","text":"FormatTime: character formated timestamp Timestamp:character current time specified format TSFormats: Format specified type","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Timestamp.html","id":"timestamp-formats","dir":"Reference","previous_headings":"","what":"Timestamp formats","title":"Create and work with timestamps — Timestamp","text":"following formats can provided TSFormats:","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Timestamp.html","id":"r","dir":"Reference","previous_headings":"","what":"R","title":"Create and work with timestamps — Timestamp","text":"24-hour R-friendly format; stores date/time information following: Four-digit year (eg. “2020” year 2020) Two-digit month (eg. “04” month April) Two-digit date (eg. “02” second day month) letter “T” 24-hour two-digit time (eg. “15” 3:00 PM) Two-digit minute (eg “05” five minutes past hour) Two-digit second (eg. “05” five seconds minute) letter “Z” results timestamp format “YYYYMMDDTHHMMSS.SSSSSSZ” (eg.  “20200402T150505Z” April 4th, 2020 3:05:05 PM). Note:  considered “R-friendly” use precise  values seconds","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Timestamp.html","id":"loom","dir":"Reference","previous_headings":"","what":"loom","title":"Create and work with timestamps — Timestamp","text":"standard format loom timestamps; stores date/time information  following: Four-digit year (eg. “2020” year 2020) Two-digit month (eg. “04” month April) Two-digit date (eg. “02” second day month) letter “T” 24-hour two-digit time (eg. “15” 3:00 PM) Two-digit minute (eg “05” five minutes past hour) Seconds precise millionth (six digits decimal) letter “Z” results timestamp format “YYYYMMDDTHHMMSS.SSSSSSZ” (eg.  “20200402T150505Z” April 4th, 2020 3:05:05 PM). Note:  considered “R-friendly” contains precise  values seconds. properly format time pretty-printing, please  remember strip precise seconds","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Timestamp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create and work with timestamps — Timestamp","text":"","code":"# \\donttest{ # Get a timestamp format srtdisk:::TSFormats() #> [1] \"%Y%m%dT%H%M%SZ\"  # Create a timestamp srtdisk:::Timestamp() #> [1] \"20260129T184630Z\"  # Format a timestamp for easy viewing time <- \"20200804T214148Z\" srtdisk:::FormatTime(time) #> [1] \"2020-08-04 17:41:48 EDT\" # }"},{"path":"https://mianaz.github.io/srtdisk/reference/Transpose.html","id":null,"dir":"Reference","previous_headings":"","what":"Transpose a matrix — Transpose","title":"Transpose a matrix — Transpose","text":"Transpose matrix","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Transpose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transpose a matrix — Transpose","text":"","code":"Transpose(x, ...)  # S3 method for class 'dgCMatrix' Transpose(x, ...)  # S3 method for class 'H5D' Transpose(   x,   dest = GetParent(x = x),   dname = paste0(\"t_\", basename(path = x$get_obj_name())),   overwrite = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'H5Group' Transpose(   x,   dest = GetParent(x = x),   dname = paste0(\"t_\", basename(path = x$get_obj_name())),   overwrite = FALSE,   ... )"},{"path":"https://mianaz.github.io/srtdisk/reference/Transpose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transpose a matrix — Transpose","text":"x matrix transpose ... Arguments passed methods dest ... dname ... overwrite ... verbose Show progress updates","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Transpose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transpose a matrix — Transpose","text":"dgCMatrix method: returns dgCMatrix data x transposed H5D H5Group methods: Invisibly returns NULL","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/UpdateKey.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a Seurat key — UpdateKey","title":"Update a Seurat key — UpdateKey","text":"Attempts validate string use Seurat key. Valid keys must match regular expression ^[[:alnum:]]+_$; key fails regular expression, attempt modify said key made removing non-alphanumeric characters, collapsing resulting vector, appending “_”. stil fails, random string lowercase characters generated, followed “_”, used key","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/UpdateKey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a Seurat key — UpdateKey","text":"","code":"UpdateKey(key)"},{"path":"https://mianaz.github.io/srtdisk/reference/UpdateKey.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a Seurat key — UpdateKey","text":"key key validate update","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/UpdateKey.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update a Seurat key — UpdateKey","text":"key, updated invalid","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/UpdateKey.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update a Seurat key — UpdateKey","text":"","code":"# \\donttest{ srtdisk:::UpdateKey(\"RNA_\") #> [1] \"RNA_\" srtdisk:::UpdateKey(\"potato\") #> [1] \"potato_\" srtdisk:::UpdateKey(\"*@)\") #> [1] \"vju_\" # }"},{"path":"https://mianaz.github.io/srtdisk/reference/UpdateSlots.html","id":null,"dir":"Reference","previous_headings":"","what":"Update slots in an object — UpdateSlots","title":"Update slots in an object — UpdateSlots","text":"Update slots object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/UpdateSlots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update slots in an object — UpdateSlots","text":"","code":"UpdateSlots(object)"},{"path":"https://mianaz.github.io/srtdisk/reference/UpdateSlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update slots in an object — UpdateSlots","text":"object object update","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/UpdateSlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update slots in an object — UpdateSlots","text":"object latest slot definitions","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ValidateLoom.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Loom Files — ValiateLoom","title":"Validate Loom Files — ValiateLoom","text":"Functions validating loom files connection","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ValidateLoom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Loom Files — ValiateLoom","text":"","code":"LoomValidate0.1(lfile, verbose = TRUE)  LoomValidate3.0.0(lfile, verbose = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/ValidateLoom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Loom Files — ValiateLoom","text":"lfile loom file object path verbose Whether print validation messages","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/ValidateLoom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Loom Files — ValiateLoom","text":"Invisibly returns TRUE valid, throws error invalid","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/WriteAttribute.html","id":null,"dir":"Reference","previous_headings":"","what":"Write an attribute to an HDF5 file, group, or dataset — WriteAttribute","title":"Write an attribute to an HDF5 file, group, or dataset — WriteAttribute","text":"Write attribute HDF5 file, group, dataset","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/WriteAttribute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write an attribute to an HDF5 file, group, or dataset — WriteAttribute","text":"","code":"WriteAttribute(x, name, lfile, stype, transpose = TRUE, verbose = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/WriteAttribute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write an attribute to an HDF5 file, group, or dataset — WriteAttribute","text":"x object write name Name store attribute lfile HDF5 file, group, dataset stype Data type attribute transpose Whether transpose data verbose Whether print messages","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/WriteAttribute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write an attribute to an HDF5 file, group, or dataset — WriteAttribute","text":"Invisibly returns NULL","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/WriteH5Group.html","id":null,"dir":"Reference","previous_headings":"","what":"Write data to an HDF5 group — WriteH5Group","title":"Write data to an HDF5 group — WriteH5Group","text":"Writing data HDF5 files can done simply usually sensible defaults. However, wanting semblance control R object written , code constructs get complicated quickly. WriteH5Group provides wrapper sensible defaults complex code constructs provide greater control data written disk. defaults chosen fit best h5Seurat files, see vignette(\"h5Seurat-spec\") details","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/WriteH5Group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write data to an HDF5 group — WriteH5Group","text":"","code":"WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'ANY' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'array' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'Assay' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'Assay5' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'data.frame' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'dgCMatrix' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'DimReduc' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'factor' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'Graph' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'list' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'logical' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'Neighbor' WriteH5Group(x, name, hgroup, verbose = TRUE)  # S4 method for class 'SeuratCommand' WriteH5Group(x, name, hgroup, verbose = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/WriteH5Group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write data to an HDF5 group — WriteH5Group","text":"x object name Name save data hgroup HDF5 file group (H5File H5Group objects hdf5r) verbose Show progress updates","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/WriteH5Group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write data to an HDF5 group — WriteH5Group","text":"Invisibly returns NULL","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/WriteH5Group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write data to an HDF5 group — WriteH5Group","text":"","code":"# \\donttest{ # Setup an HDF5 file hfile <- hdf5r::H5File$new(filename = tempfile(fileext = '.h5'), mode = 'a') # }  # \\donttest{ # Data frames are stored as either datasets or groups, depending on the # presence of factor columns df <- data.frame(   x = c('g1', 'g1', 'g2', 'g1', 'g2'),   y = 1:5,   stringsAsFactors = FALSE )  # When no factor columns are present, the data frame is written as a single # HDF5 compound dataset WriteH5Group(x = df, name = 'df', hgroup = hfile) hfile[['df']] #> Class: H5Group #> Filename: /private/var/folders/9l/bl67cpdj3rzgkx2pfk0flmhc0000gn/T/RtmpwC7ZDD/file9faa31d588d.h5 #> Group: /df #> Attributes: colnames, _index #> Listing: #>    name    obj_type dataset.dims dataset.type_class #>  _index H5I_DATASET            5         H5T_STRING #>       x H5I_DATASET            5         H5T_STRING #>       y H5I_DATASET            5        H5T_INTEGER  # When factors are present, the data frame is written as a group # This is because h5py does not implement HDF5 Enums, so factor level # information would be lost df$x <- factor(x = df$x) WriteH5Group(x = df, name = 'df.factor', hgroup = hfile) hfile[['df.factor']] #> Class: H5Group #> Filename: /private/var/folders/9l/bl67cpdj3rzgkx2pfk0flmhc0000gn/T/RtmpwC7ZDD/file9faa31d588d.h5 #> Group: /df.factor #> Attributes: colnames, _index #> Listing: #>    name    obj_type dataset.dims dataset.type_class #>  _index H5I_DATASET            5         H5T_STRING #>       x   H5I_GROUP         <NA>               <NA> #>       y H5I_DATASET            5        H5T_INTEGER # }  # \\donttest{ # Factors turn into a group with two components: values and levels # This is to preserve level information for HDF5 APIs that don't implement # the HDF5 Enum type (eg. h5py) # values corresponds to the integer values of each member of a factor # levels is a string dataset with one entry per level fctr <- factor(x = c('g1', 'g1', 'g2', 'g1', 'g2')) WriteH5Group(x = fctr, name = 'factor', hgroup = hfile) hfile[['factor']] #> Class: H5Group #> Filename: /private/var/folders/9l/bl67cpdj3rzgkx2pfk0flmhc0000gn/T/RtmpwC7ZDD/file9faa31d588d.h5 #> Group: /factor #> Listing: #>    name    obj_type dataset.dims dataset.type_class #>  levels H5I_DATASET            2         H5T_STRING #>  values H5I_DATASET            5        H5T_INTEGER # }  # \\donttest{ # Logicals get encoded as integers with the following mapping # FALSE becomes 0L # TRUE becomes 1L # NA becomes 2L # These are stored as H5T_INTEGERS instead of H5T_LOGICALS # Additionally, an attribute called \"s3class\" is written with the value of \"logical\" WriteH5Group(c(TRUE, FALSE, NA), name = \"logicals\", hgroup = hfile) hfile[[\"logicals\"]] #> Class: H5D #> Dataset: /logicals #> Filename: /private/var/folders/9l/bl67cpdj3rzgkx2pfk0flmhc0000gn/T/RtmpwC7ZDD/file9faa31d588d.h5 #> Access type: H5F_ACC_RDWR #> Attributes: s3class #> Datatype: H5T_STD_I32LE #> Space: Type=Simple     Dims=3     Maxdims=Inf #> Chunk: 2048 hfile[[\"logicals\"]]$attr_open(\"s3class\")$read() #> [1] \"logical\" # }  # \\donttest{ # Close and remove the HDF5 file hfile$close_all() file.remove(hfile$filename) #> [1] TRUE # }"},{"path":"https://mianaz.github.io/srtdisk/reference/WriteMode.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the proper HDF5 connection mode for writing depending on overwrite status — WriteMode","title":"Get the proper HDF5 connection mode for writing depending on overwrite status — WriteMode","text":"Get proper HDF5 connection mode writing depending overwrite status","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/WriteMode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the proper HDF5 connection mode for writing depending on overwrite status — WriteMode","text":"","code":"WriteMode(overwrite = FALSE)"},{"path":"https://mianaz.github.io/srtdisk/reference/WriteMode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the proper HDF5 connection mode for writing depending on overwrite status — WriteMode","text":"overwrite Overwrite file","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/WriteMode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the proper HDF5 connection mode for writing depending on overwrite status — WriteMode","text":"w overwrite else w-","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/WriteMode.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the proper HDF5 connection mode for writing depending on overwrite status — WriteMode","text":"","code":"# \\donttest{ srtdisk:::WriteMode(TRUE) #> [1] \"w\" srtdisk:::WriteMode(FALSE) #> [1] \"w-\" # }"},{"path":"https://mianaz.github.io/srtdisk/reference/Writeable.html","id":null,"dir":"Reference","previous_headings":"","what":"Is an HDF5 file or group writeable — Writeable","title":"Is an HDF5 file or group writeable — Writeable","text":"HDF5 file group writeable","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Writeable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is an HDF5 file or group writeable — Writeable","text":"","code":"Writeable(x, error = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/Writeable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is an HDF5 file or group writeable — Writeable","text":"x H5File H5Group object error Throw error x writeable","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/Writeable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is an HDF5 file or group writeable — Writeable","text":"TRUE x writeable otherwise FALSE","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5SI.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools for handling h5Seurat indexes — h5SI","title":"Tools for handling h5Seurat indexes — h5SI","text":"Tools handling h5Seurat indexes","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5SI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tools for handling h5Seurat indexes — h5SI","text":"","code":"# S3 method for class 'h5SI' DefaultAssay(object, ...)  # S3 method for class 'h5SI' print(x, ...)"},{"path":"https://mianaz.github.io/srtdisk/reference/h5SI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools for handling h5Seurat indexes — h5SI","text":"x, object h5Seurat index (h5SI)","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5SI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tools for handling h5Seurat indexes — h5SI","text":"DefaultAssay: assay set default assay print: Invisibly returns x","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-bindings.html","id":null,"dir":"Reference","previous_headings":"","what":"Seurat bindings for h5Seurat files — h5Seurat-bindings","title":"Seurat bindings for h5Seurat files — h5Seurat-bindings","text":"Seurat bindings h5Seurat files","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-bindings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Seurat bindings for h5Seurat files — h5Seurat-bindings","text":"","code":"# S3 method for class 'h5Seurat' Cells(x, ...)  # S3 method for class 'h5Seurat' DefaultAssay(object, ...)  # S3 method for class 'h5Seurat' DefaultAssay(object, ...) <- value  # S3 method for class 'h5Seurat' Idents(object, ...)  # S3 method for class 'H5Group' IsGlobal(object, ...)  # S3 method for class 'H5Group' Key(object, ...)  # S3 method for class 'h5Seurat' Project(object, ...)  # S3 method for class 'h5Seurat' Project(object, ...) <- value  # S3 method for class 'h5Seurat' Stdev(object, reduction = \"pca\", ...)"},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-bindings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Seurat bindings for h5Seurat files — h5Seurat-bindings","text":"x h5Seurat object object h5Seurat H5Group object reduction Name dimensional reduction (default: \"pca\") value Value set ... Additional arguments passed methods","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":null,"dir":"Reference","previous_headings":"","what":"A class for connections to h5Seurat files — h5Seurat-class","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"class connections h5Seurat files class connections h5Seurat files","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"R6Class object","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"hdf5r::H5RefClass -> hdf5r::H5File -> srtdisk::scdisk -> h5Seurat","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"hdf5r::H5RefClass$close() hdf5r::H5RefClass$dec_ref() hdf5r::H5RefClass$get_file_id() hdf5r::H5RefClass$get_obj_type() hdf5r::H5RefClass$get_ref() hdf5r::H5RefClass$inc_ref() hdf5r::H5RefClass$methods() hdf5r::H5File$attr_delete() hdf5r::H5File$attr_delete_by_idx() hdf5r::H5File$attr_delete_by_name() hdf5r::H5File$attr_exists() hdf5r::H5File$attr_exists_by_name() hdf5r::H5File$attr_get_number() hdf5r::H5File$attr_info_by_idx() hdf5r::H5File$attr_info_by_name() hdf5r::H5File$attr_name_by_idx() hdf5r::H5File$attr_open() hdf5r::H5File$attr_open_by_idx() hdf5r::H5File$attr_open_by_name() hdf5r::H5File$attr_rename() hdf5r::H5File$attr_rename_by_name() hdf5r::H5File$close_all() hdf5r::H5File$commit() hdf5r::H5File$create_attr() hdf5r::H5File$create_attr_by_name() hdf5r::H5File$create_dataset() hdf5r::H5File$create_group() hdf5r::H5File$create_reference() hdf5r::H5File$exists() hdf5r::H5File$file_info() hdf5r::H5File$flush() hdf5r::H5File$get_filename() hdf5r::H5File$get_filesize() hdf5r::H5File$get_intent() hdf5r::H5File$get_obj_count() hdf5r::H5File$get_obj_ids() hdf5r::H5File$get_obj_name() hdf5r::H5File$group_info() hdf5r::H5File$group_info_by_idx() hdf5r::H5File$group_info_by_name() hdf5r::H5File$link() hdf5r::H5File$link_copy_from() hdf5r::H5File$link_copy_to() hdf5r::H5File$link_create_external() hdf5r::H5File$link_create_hard() hdf5r::H5File$link_create_soft() hdf5r::H5File$link_delete() hdf5r::H5File$link_delete_by_idx() hdf5r::H5File$link_exists() hdf5r::H5File$link_info() hdf5r::H5File$link_info_by_idx() hdf5r::H5File$link_move_from() hdf5r::H5File$link_move_to() hdf5r::H5File$link_name_by_idx() hdf5r::H5File$link_value() hdf5r::H5File$link_value_by_idx() hdf5r::H5File$ls() hdf5r::H5File$mount() hdf5r::H5File$obj_copy_from() hdf5r::H5File$obj_copy_to() hdf5r::H5File$obj_info() hdf5r::H5File$obj_info_by_idx() hdf5r::H5File$obj_info_by_name() hdf5r::H5File$open() hdf5r::H5File$open_by_idx() hdf5r::H5File$path_valid() hdf5r::H5File$print() hdf5r::H5File$unmount() srtdisk::scdisk$chunk.points() srtdisk::scdisk$finalizer() srtdisk::scdisk$initialize() srtdisk::scdisk$last.modified() srtdisk::scdisk$timestamp()","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"h5Seurat$index() h5Seurat$set.version() h5Seurat$version()","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"method-index-","dir":"Reference","previous_headings":"","what":"Method index()","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"Get index h5Seurat file","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"","code":"h5Seurat$index()"},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"method-set-version-","dir":"Reference","previous_headings":"","what":"Method set.version()","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"Set version attribute","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"","code":"h5Seurat$set.version(version)"},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"version version number matching regex ^\\d+(\\.\\d+){2}(\\.9\\d{3})?$","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"method-version-","dir":"Reference","previous_headings":"","what":"Method version()","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"Get version attribute","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/h5Seurat-class.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"A class for connections to h5Seurat files — h5Seurat-class","text":"","code":"h5Seurat$version()"},{"path":"https://mianaz.github.io/srtdisk/reference/loom-bindings.html","id":null,"dir":"Reference","previous_headings":"","what":"Seurat binding for loom files — loom-bindings","title":"Seurat binding for loom files — loom-bindings","text":"Seurat binding loom files","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-bindings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Seurat binding for loom files — loom-bindings","text":"","code":"# S3 method for class 'loom' DefaultAssay(object, ...)  # S3 method for class 'loom' dim(x)"},{"path":"https://mianaz.github.io/srtdisk/reference/loom-bindings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Seurat binding for loom files — loom-bindings","text":"object loom object x loom object ... Additional arguments passed methods","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":null,"dir":"Reference","previous_headings":"","what":"A class for connections to loom files — loom-class","title":"A class for connections to loom files — loom-class","text":"class connections loom files class connections loom files","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A class for connections to loom files — loom-class","text":"R6Class object","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"A class for connections to loom files — loom-class","text":"hdf5r::H5RefClass -> hdf5r::H5File -> srtdisk::scdisk -> loom","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"A class for connections to loom files — loom-class","text":"hdf5r::H5RefClass$close() hdf5r::H5RefClass$dec_ref() hdf5r::H5RefClass$get_file_id() hdf5r::H5RefClass$get_obj_type() hdf5r::H5RefClass$get_ref() hdf5r::H5RefClass$inc_ref() hdf5r::H5RefClass$methods() hdf5r::H5File$attr_delete() hdf5r::H5File$attr_delete_by_idx() hdf5r::H5File$attr_delete_by_name() hdf5r::H5File$attr_exists() hdf5r::H5File$attr_exists_by_name() hdf5r::H5File$attr_get_number() hdf5r::H5File$attr_info_by_idx() hdf5r::H5File$attr_info_by_name() hdf5r::H5File$attr_name_by_idx() hdf5r::H5File$attr_open() hdf5r::H5File$attr_open_by_idx() hdf5r::H5File$attr_open_by_name() hdf5r::H5File$attr_rename() hdf5r::H5File$attr_rename_by_name() hdf5r::H5File$close_all() hdf5r::H5File$commit() hdf5r::H5File$create_attr() hdf5r::H5File$create_attr_by_name() hdf5r::H5File$create_dataset() hdf5r::H5File$create_group() hdf5r::H5File$create_reference() hdf5r::H5File$exists() hdf5r::H5File$file_info() hdf5r::H5File$flush() hdf5r::H5File$get_filename() hdf5r::H5File$get_filesize() hdf5r::H5File$get_intent() hdf5r::H5File$get_obj_count() hdf5r::H5File$get_obj_ids() hdf5r::H5File$get_obj_name() hdf5r::H5File$group_info() hdf5r::H5File$group_info_by_idx() hdf5r::H5File$group_info_by_name() hdf5r::H5File$link() hdf5r::H5File$link_copy_from() hdf5r::H5File$link_copy_to() hdf5r::H5File$link_create_external() hdf5r::H5File$link_create_hard() hdf5r::H5File$link_create_soft() hdf5r::H5File$link_delete() hdf5r::H5File$link_delete_by_idx() hdf5r::H5File$link_exists() hdf5r::H5File$link_info() hdf5r::H5File$link_info_by_idx() hdf5r::H5File$link_move_from() hdf5r::H5File$link_move_to() hdf5r::H5File$link_name_by_idx() hdf5r::H5File$link_value() hdf5r::H5File$link_value_by_idx() hdf5r::H5File$ls() hdf5r::H5File$mount() hdf5r::H5File$obj_copy_from() hdf5r::H5File$obj_copy_to() hdf5r::H5File$obj_info() hdf5r::H5File$obj_info_by_idx() hdf5r::H5File$obj_info_by_name() hdf5r::H5File$open() hdf5r::H5File$open_by_idx() hdf5r::H5File$path_valid() hdf5r::H5File$print() hdf5r::H5File$unmount() srtdisk::scdisk$chunk.points() srtdisk::scdisk$finalizer() srtdisk::scdisk$initialize()","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"A class for connections to loom files — loom-class","text":"loom$add_attribute() loom$add_graph() loom$add_layer() loom$version() loom$timestamp() loom$last.modified()","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"method-add-attribute-","dir":"Reference","previous_headings":"","what":"Method add_attribute()","title":"A class for connections to loom files — loom-class","text":"Add attribute","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A class for connections to loom files — loom-class","text":"","code":"loom$add_attribute(x, name, type = c(\"global\", \"row\", \"col\"))"},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A class for connections to loom files — loom-class","text":"x Object add attribute name Name store attribute type Type attribute add","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"method-add-graph-","dir":"Reference","previous_headings":"","what":"Method add_graph()","title":"A class for connections to loom files — loom-class","text":"Add graph","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"A class for connections to loom files — loom-class","text":"","code":"loom$add_graph(x, name, type = c(\"col\", \"row\"), verbose = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"A class for connections to loom files — loom-class","text":"x ... name ... type ... verbose ...","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"method-add-layer-","dir":"Reference","previous_headings":"","what":"Method add_layer()","title":"A class for connections to loom files — loom-class","text":"Add layer loom file","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"A class for connections to loom files — loom-class","text":"","code":"loom$add_layer(x, name, transpose = TRUE, verbose = TRUE)"},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"A class for connections to loom files — loom-class","text":"x object save layer name Name store layer transpose ... verbose ...","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"A class for connections to loom files — loom-class","text":"Invisibly returns NULL","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"method-version-","dir":"Reference","previous_headings":"","what":"Method version()","title":"A class for connections to loom files — loom-class","text":"Get version information","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"A class for connections to loom files — loom-class","text":"","code":"loom$version()"},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"A class for connections to loom files — loom-class","text":"numeric_version object loom specification version information","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"method-timestamp-","dir":"Reference","previous_headings":"","what":"Method timestamp()","title":"A class for connections to loom files — loom-class","text":"Add timestamp dataset group HDF5 attribute","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"A class for connections to loom files — loom-class","text":"","code":"loom$timestamp(name = NULL)"},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"A class for connections to loom files — loom-class","text":"name Name dataset group add timestamp ; NULL, timestamps file whole","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"returns-2","dir":"Reference","previous_headings":"","what":"Returns","title":"A class for connections to loom files — loom-class","text":"Invisibly returns object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"method-last-modified-","dir":"Reference","previous_headings":"","what":"Method last.modified()","title":"A class for connections to loom files — loom-class","text":"Retrieve timestamp dataset group","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"A class for connections to loom files — loom-class","text":"","code":"loom$last.modified(name = NULL, locale = FALSE)"},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"A class for connections to loom files — loom-class","text":"name Name dataset group retrieve timestamp ; NULL, retrieves timestamp file-level locale Change timestamp timezone locale","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/loom-class.html","id":"returns-3","dir":"Reference","previous_headings":"","what":"Returns","title":"A class for connections to loom files — loom-class","text":"character timestamp","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":null,"dir":"Reference","previous_headings":"","what":"A disk-based object for single-cell analysis — scdisk-class","title":"A disk-based object for single-cell analysis — scdisk-class","text":"disk-based object single-cell analysis disk-based object single-cell analysis","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A disk-based object for single-cell analysis — scdisk-class","text":"R6Class object","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"A disk-based object for single-cell analysis — scdisk-class","text":"hdf5r::H5RefClass -> hdf5r::H5File -> scdisk","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"A disk-based object for single-cell analysis — scdisk-class","text":"hdf5r::H5RefClass$close() hdf5r::H5RefClass$dec_ref() hdf5r::H5RefClass$get_file_id() hdf5r::H5RefClass$get_obj_type() hdf5r::H5RefClass$get_ref() hdf5r::H5RefClass$inc_ref() hdf5r::H5RefClass$methods() hdf5r::H5File$attr_delete() hdf5r::H5File$attr_delete_by_idx() hdf5r::H5File$attr_delete_by_name() hdf5r::H5File$attr_exists() hdf5r::H5File$attr_exists_by_name() hdf5r::H5File$attr_get_number() hdf5r::H5File$attr_info_by_idx() hdf5r::H5File$attr_info_by_name() hdf5r::H5File$attr_name_by_idx() hdf5r::H5File$attr_open() hdf5r::H5File$attr_open_by_idx() hdf5r::H5File$attr_open_by_name() hdf5r::H5File$attr_rename() hdf5r::H5File$attr_rename_by_name() hdf5r::H5File$close_all() hdf5r::H5File$commit() hdf5r::H5File$create_attr() hdf5r::H5File$create_attr_by_name() hdf5r::H5File$create_dataset() hdf5r::H5File$create_group() hdf5r::H5File$create_reference() hdf5r::H5File$exists() hdf5r::H5File$file_info() hdf5r::H5File$flush() hdf5r::H5File$get_filename() hdf5r::H5File$get_filesize() hdf5r::H5File$get_intent() hdf5r::H5File$get_obj_count() hdf5r::H5File$get_obj_ids() hdf5r::H5File$get_obj_name() hdf5r::H5File$group_info() hdf5r::H5File$group_info_by_idx() hdf5r::H5File$group_info_by_name() hdf5r::H5File$link() hdf5r::H5File$link_copy_from() hdf5r::H5File$link_copy_to() hdf5r::H5File$link_create_external() hdf5r::H5File$link_create_hard() hdf5r::H5File$link_create_soft() hdf5r::H5File$link_delete() hdf5r::H5File$link_delete_by_idx() hdf5r::H5File$link_exists() hdf5r::H5File$link_info() hdf5r::H5File$link_info_by_idx() hdf5r::H5File$link_move_from() hdf5r::H5File$link_move_to() hdf5r::H5File$link_name_by_idx() hdf5r::H5File$link_value() hdf5r::H5File$link_value_by_idx() hdf5r::H5File$ls() hdf5r::H5File$mount() hdf5r::H5File$obj_copy_from() hdf5r::H5File$obj_copy_to() hdf5r::H5File$obj_info() hdf5r::H5File$obj_info_by_idx() hdf5r::H5File$obj_info_by_name() hdf5r::H5File$open() hdf5r::H5File$open_by_idx() hdf5r::H5File$path_valid() hdf5r::H5File$print() hdf5r::H5File$unmount()","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"A disk-based object for single-cell analysis — scdisk-class","text":"scdisk$new() scdisk$finalizer() scdisk$chunk.points() scdisk$timestamp() scdisk$last.modified()","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"A disk-based object for single-cell analysis — scdisk-class","text":"Create new scdisk object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A disk-based object for single-cell analysis — scdisk-class","text":"","code":"scdisk$new(   filename = NULL,   mode = c(\"a\", \"r\", \"r+\", \"w\", \"w-\", \"x\"),   validate = TRUE,   ... )"},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A disk-based object for single-cell analysis — scdisk-class","text":"filename Name -disk file connect mode open file, choose : Create new open existing file, allow read write r Open existing file, allow read r+ Open existing file, allow read write w Create new file (deleting existing one), allow read write w-, x Create new file (error exists), allow read write validate Validate file upon connection ... Extra arguments passed validation routine","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"method-finalizer-","dir":"Reference","previous_headings":"","what":"Method finalizer()","title":"A disk-based object for single-cell analysis — scdisk-class","text":"Handle loss reference scdisk object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"A disk-based object for single-cell analysis — scdisk-class","text":"","code":"scdisk$finalizer()"},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"method-chunk-points-","dir":"Reference","previous_headings":"","what":"Method chunk.points()","title":"A disk-based object for single-cell analysis — scdisk-class","text":"Generate chunk points dataset","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"A disk-based object for single-cell analysis — scdisk-class","text":"","code":"scdisk$chunk.points(   dataset,   MARGIN = getOption(x = \"srtdisk.chunking.MARGIN\", default = \"largest\"),   csize = NULL )"},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"A disk-based object for single-cell analysis — scdisk-class","text":"dataset Name dataset MARGIN Direction chunk ; defaults largest dimension dataset csize Size chunk; defaults hdf5r-suggested chunk size","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"A disk-based object for single-cell analysis — scdisk-class","text":"matrix row chunk, column 1 start points, column 2 end points","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"method-timestamp-","dir":"Reference","previous_headings":"","what":"Method timestamp()","title":"A disk-based object for single-cell analysis — scdisk-class","text":"Add timestamp dataset group HDF5 attribute","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"A disk-based object for single-cell analysis — scdisk-class","text":"","code":"scdisk$timestamp(   name = NULL,   attr = \"ts\",   tz = \"UTC\",   format = TSFormats(type = \"R\") )"},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"A disk-based object for single-cell analysis — scdisk-class","text":"name Name dataset group add timestamp ; NULL, timestamps file whole attr Name attribute store timestamp ass tz, format See Timestamp","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"A disk-based object for single-cell analysis — scdisk-class","text":"Invisilby returns object","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"method-last-modified-","dir":"Reference","previous_headings":"","what":"Method last.modified()","title":"A disk-based object for single-cell analysis — scdisk-class","text":"Retrieve timestamp dataset group","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"A disk-based object for single-cell analysis — scdisk-class","text":"","code":"scdisk$last.modified(   name = NULL,   attr = \"ts\",   locale = TRUE,   tz = \"UTC\",   format = TSFormats(type = \"R\") )"},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"A disk-based object for single-cell analysis — scdisk-class","text":"name Name dataset group retrieve timestamp ; NULL, retrieves timestamp file-level attr Name attribute retrieve timestamp locale Change timestamp timezone locale tz, format See Timestamp","code":""},{"path":"https://mianaz.github.io/srtdisk/reference/scdisk-class.html","id":"returns-2","dir":"Reference","previous_headings":"","what":"Returns","title":"A disk-based object for single-cell analysis — scdisk-class","text":"character timestamp","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"srtdisk-020","dir":"Changelog","previous_headings":"","what":"srtdisk 0.2.0","title":"srtdisk 0.2.0","text":"Release Date: 2026-01-22","code":""},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"full-scrna-seq-conversion-support-with-seurat-v5-0-2-0","dir":"Changelog","previous_headings":"Highlights","what":"Full scRNA-seq Conversion Support with Seurat v5","title":"srtdisk 0.2.0","text":"srtdisk now provides complete bidirectional conversion Seurat objects h5ad format, full compatibility Seurat v5’s new Assay5 architecture: Seurat → h5ad: Use SeuratToH5AD() direct one-step conversion traditional two-step SaveH5Seurat() + Convert() workflow h5ad → Seurat: Use Convert() + LoadH5Seurat() import scanpy/AnnData objects Properly handles V5 layered data structure (counts, data, scale.data layers) Supports multi-assay objects (e.g., CITE-seq RNA + ADT)","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"metadata-preservation-fixes-0-2-0","dir":"Changelog","previous_headings":"Highlights","what":"Metadata Preservation Fixes","title":"srtdisk 0.2.0","text":"Fixed categorical metadata loss: Factor/categorical variables obs now correctly preserved h5ad conversion instead dropped converted strings Improved handling cell-level feature-level metadata round-trip conversions","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"spatial-data-support-visium-0-2-0","dir":"Changelog","previous_headings":"Highlights","what":"Spatial Data Support (Visium)","title":"srtdisk 0.2.0","text":"Preserves spatial coordinates, scale factors, tissue images Compatible scanpy/squidpy spatial analysis workflows h5ad → Seurat: Spatial conversion fully supported Fixed spatial coordinate X/Y orientation scanpy compatibility","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"new-features-0-2-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"srtdisk 0.2.0","text":"SeuratToH5AD() wrapper function convenient direct conversion Enhanced Visium spatial data conversion proper coordinate handling Support SlideSeq FOV-based spatial technologies (experimental) Improved scanpy-compatible naming conventions standardize = TRUE","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"bug-fixes-0-2-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"srtdisk 0.2.0","text":"Fixed categorical metadata loss h5ad conversion Fixed “attribute already exists” error converting h5ad graphs h5seurat Fixed GetAssayDataCompat() SetAssayDataCompat() use layer parameter (SeuratObject 5.0+ requirement) Fixed spatial coordinate X/Y flip h5Seurat h5ad conversion Improved UMAP display h5ad Seurat tutorial","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"documentation-0-2-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"srtdisk 0.2.0","text":"Comprehensive README quick start conversion examples Comparison table: srtdisk vs SeuratDisk feature improvements Multi-assay (CITE-seq) conversion documentation Spatial data conversion examples (beta)","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"known-limitations-0-2-0","dir":"Changelog","previous_headings":"","what":"Known Limitations","title":"srtdisk 0.2.0","text":"Multi-assay conversion requires separate h5ad files per assay (AnnData limitation) Large datasets may require sufficient memory -memory conversion","code":""},{"path":[]},{"path":[]},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"direct-seurat-to-h5ad-conversion-0-1-0","dir":"Changelog","previous_headings":"New Features","what":"Direct Seurat to H5AD Conversion","title":"srtdisk 0.1.0","text":"Added SeuratToH5AD() function direct conversion Seurat objects H5AD format Automatically handles intermediate h5Seurat file creation cleanup Supports Convert() parameters including standardize scanpy-compatible naming","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"improved-spatial-data-support-0-1-0","dir":"Changelog","previous_headings":"New Features","what":"Improved Spatial Data Support","title":"srtdisk 0.1.0","text":"Enhanced Visium spatial data conversion h5Seurat h5ad formats Better handling multi-library spatial datasets Improved coordinate transformation scale factor preservation","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"seurat-v5-compatibility-0-1-0","dir":"Changelog","previous_headings":"New Features","what":"Seurat v5 Compatibility","title":"srtdisk 0.1.0","text":"Full support Seurat v5 Assay5 objects Fixed SeuratObject 5.0+ API compatibility (layer vs slot parameters) Proper handling V5 layered data structure conversions","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"bug-fixes-0-1-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"srtdisk 0.1.0","text":"Fixed spatial coordinate X/Y flip h5Seurat h5ad conversion (coordinates now correctly stored [X, Y] scanpy/squidpy) Fixed “attribute already exists” error converting h5ad graphs h5seurat Fixed GetAssayDataCompat() SetAssayDataCompat() use layer parameter (SeuratObject 5.0+ requirement) Fixed vignette assay references (using correct RNA assay instead non-existent SCT/Spatial)","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"code-improvements-0-1-0","dir":"Changelog","previous_headings":"","what":"Code Improvements","title":"srtdisk 0.1.0","text":"Removed unused utility functions (WithAssayCompat, GetSlotMapping, GetSeuratSlotMapping, ValidateSlotMapping) Removed deprecated SafeExistsDeprecated function Simplified verbose messaging AssembleObject.R Extracted CreateFakeCellNames helper reduce code duplication Convert.R Removed dead commented-code","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"documentation-0-1-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"srtdisk 0.1.0","text":"Updated vignettes Python/reticulate integration scanpy/squidpy examples Added conditional evaluation Python chunks based package availability Improved vignette examples bundled test data Added cellxgene spatial dataset download examples","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"test-infrastructure-0-1-0","dir":"Changelog","previous_headings":"","what":"Test Infrastructure","title":"srtdisk 0.1.0","text":"Simplified test suite: consolidated 4 test files single focused test-conversion.R CellxGene colorectal cancer sample (935 cells) h5ad testing pbmc3k.final SeuratData Seurat testing stxBrain anterior1 SeuratData Visium spatial testing Removed synthetic test data favor real-world datasets Added UpdateSeuratObject() calls compatibility older SeuratData objects","code":""},{"path":"https://mianaz.github.io/srtdisk/news/index.html","id":"test-data-0-1-0","dir":"Changelog","previous_headings":"","what":"Test Data","title":"srtdisk 0.1.0","text":"Replaced pbmc_small.rds crc_sample.h5ad (CellxGene colorectal cancer, 935 cells x 25,344 genes) Vignettes now use SeuratData (pbmc3k.final, stxBrain) instead bundled files","code":""}]
